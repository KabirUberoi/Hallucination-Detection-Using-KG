{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 12:35:38 - INFO - \t missing_keys: []\n",
      "07/04/2024 12:35:38 - INFO - \t unexpected_keys: []\n",
      "07/04/2024 12:35:38 - INFO - \t mismatched_keys: []\n",
      "07/04/2024 12:35:38 - INFO - \t error_msgs: []\n",
      "07/04/2024 12:35:38 - INFO - \t Model Parameters: 590.0M, Transformer: 434.6M, Coref head: 155.4M\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.tokens import Doc, Span\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('dbpedia_spotlight', config={'confidence': 0.5})\n",
    "preprocessing = spacy.load('en_core_web_sm')\n",
    "from fastcoref import LingMessCoref\n",
    "coref_model = LingMessCoref()\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"potsawee/wiki_bio_gpt3_hallucination\")\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import concurrent.futures\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 12:35:54 - INFO - \t Use pytorch device_name: mps\n",
      "07/04/2024 12:35:54 - INFO - \t Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
      "/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cluster_spans(doc, clusters):\n",
    "    fast_clusters = []\n",
    "    for cluster in clusters:\n",
    "        new_group = []\n",
    "        for start, end in cluster:\n",
    "            span = doc.char_span(start, end)\n",
    "            if span is not None:\n",
    "                new_group.append([span.start, span.end - 1])\n",
    "        fast_clusters.append(new_group)\n",
    "    return fast_clusters\n",
    "\n",
    "def get_clusters(doc, text):\n",
    "    preds = coref_model.predict(texts=[text])\n",
    "    # print(f\"\\nThe clusters of same entities are as follows: {preds[0].get_clusters(as_strings=True)} \\n\")\n",
    "    clusters = preds[0].get_clusters(as_strings=False)\n",
    "    cluster_spans = get_cluster_spans(doc, clusters)\n",
    "    return cluster_spans\n",
    "\n",
    "def get_span_noun_indices(doc, cluster):    \n",
    "    spans = [doc[start:end+1] for start, end in cluster]\n",
    "\n",
    "    spans_pos = []\n",
    "    for span in spans:\n",
    "        pos_tags = [token.pos_ for token in span]\n",
    "        spans_pos.append(pos_tags)\n",
    "\n",
    "    noun_indices = []\n",
    "    for i, pos_list in enumerate(spans_pos):\n",
    "        if 'NOUN' in pos_list or 'PROPN' in pos_list:\n",
    "            noun_indices.append(i)\n",
    "    return noun_indices\n",
    "\n",
    "def get_cluster_head(doc, cluster, noun_indices):\n",
    "    head_idx = noun_indices[0]\n",
    "    head_start, head_end = cluster[head_idx]\n",
    "    head_span = doc[head_start:head_end+1]\n",
    "    return head_span, [head_start, head_end]\n",
    "\n",
    "def is_containing_other_spans(span, all_spans):\n",
    "    for s in all_spans:\n",
    "        if s[0] >= span[0] and s[1] <= span[1] and s != span:\n",
    "            return True  \n",
    "    return False\n",
    "\n",
    "def replacement(coref, resolved, mention_span):\n",
    "    start, end = coref\n",
    "    mention_text = mention_span.text_with_ws + \" \"\n",
    "    resolved[start] = mention_text\n",
    "    for i in range(start + 1, end + 1):\n",
    "        resolved[i] = \"\"\n",
    "    return resolved\n",
    "\n",
    "def replace_corefs(document, clusters):\n",
    "    resolved = [token.text_with_ws for token in document]\n",
    "    all_spans = [span for cluster in clusters for span in cluster]\n",
    "\n",
    "    for cluster in clusters:\n",
    "        noun_indices = get_span_noun_indices(document, cluster)\n",
    "\n",
    "        if noun_indices:\n",
    "            mention_span, mention = get_cluster_head(document, cluster, noun_indices)\n",
    "        else:\n",
    "            start, end = cluster[0]\n",
    "            mention_span = document[start:end+1]\n",
    "            mention = cluster[0]\n",
    "            \n",
    "        for coref in cluster:\n",
    "            resolved = replacement(coref, resolved, mention_span)\n",
    "\n",
    "    \n",
    "    return (\"\".join(resolved))\n",
    "\n",
    "\n",
    "def coreference_resolution(text):\n",
    "    doc = nlp(text)\n",
    "    clusters = get_clusters(doc, text) \n",
    "    answer= replace_corefs(doc, clusters) \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_three_word_name(entity):\n",
    "    return len(entity.text.split()) >= 3 and entity.label_ == \"PERSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_three_worded_names(text):\n",
    "    doc = preprocessing(text)\n",
    "    new_text = text\n",
    "    \n",
    "    for entity in doc.ents:\n",
    "        if is_three_word_name(entity):\n",
    "            words = entity.text.split()\n",
    "            new_name = f\"{words[0]} {words[-1]}\"\n",
    "            new_text = new_text.replace(entity.text, new_name)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text): \n",
    "    # text = replace_three_worded_names(text) \n",
    "    text = re.sub(r'[^\\w\\s.,()\\'\"\\-]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r\"(['\\\"])\\1+\", r\"\\1\", text)\n",
    "    # preprocessed_text = coreference_resolution(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotlight Based System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Based Link Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_based_links(text):\n",
    "    final_text = coreference_resolution(text)\n",
    "    doc = nlp(final_text)\n",
    "    final_sents = [sents for sents in doc.sents]\n",
    "    # entities = list(doc.ents)\n",
    "    # print(\"Entities found by spaCy:\", entities)\n",
    "    \n",
    "    subjects = []\n",
    "    subject_set = set([])\n",
    "    for sent in doc.sents:\n",
    "        found_subject = False\n",
    "        for token in sent:\n",
    "            # print(f\"{token},{token.dep_}\")\n",
    "            if token.dep_ in ['nsubj', 'nsubjpass'] and token.ent_kb_id_:\n",
    "                subjects.append(token.ent_kb_id_)\n",
    "                subject_set.add(token.ent_kb_id_)\n",
    "                found_subject = True\n",
    "                break\n",
    "        if not found_subject:\n",
    "            for i, token in enumerate(sent):\n",
    "                if token.dep_ in [\"dobj\",\"iobj\",\"pobj\"]:\n",
    "                    subjects.append(token.ent_kb_id_)\n",
    "                    subject_set.add(token.ent_kb_id_)\n",
    "                    found_subject = True\n",
    "                    break\n",
    "        if not found_subject:\n",
    "            subjects.append(None)\n",
    "    (\"Subjects identified:\", subjects)\n",
    "    \n",
    "    sentence_forms = []\n",
    "    for sent in doc.sents:\n",
    "        entities = [(ent.text, ent.start, ent.end) for ent in sent.ents]\n",
    "        sentence_forms.append(entities)\n",
    "    # print(\"Entities in each sentence:\", sentence_forms)\n",
    "    \n",
    "    # print(subjects)\n",
    "    \n",
    "    pairs = []\n",
    "    count = 0\n",
    "    for i in range(len(sentence_forms)):\n",
    "        tmp_storage = []\n",
    "        if subjects[i] is not None and len(sentence_forms[i]) > 1:\n",
    "            for entity, ent_start, ent_end in sentence_forms[i]:\n",
    "                check_sub = False\n",
    "                for token in doc[ent_start:ent_end]:\n",
    "                    if token.dep_ in ['nsubj', 'nsubjpass']:\n",
    "                        check_sub = True\n",
    "                        break\n",
    "                if check_sub == True or entity in subjects:\n",
    "                    continue\n",
    "                tmp_storage.append([subjects[i], entity])\n",
    "                count += 1\n",
    "        pairs.append(tmp_storage)\n",
    "    print(f\"The number of pairs is: {count}\\n\")\n",
    "    \n",
    "    return pairs, final_sents, subject_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_based_links(text):\n",
    "    final_text = coreference_resolution(text)\n",
    "    doc = nlp(final_text)\n",
    "    final_sents = [sents for sents in doc.sents]\n",
    "    # entities = list(doc.ents)\n",
    "    # print(\"Entities found by spaCy:\", entities)\n",
    "    \n",
    "    subjects = []\n",
    "    subject_set = set([])\n",
    "    for sent in doc.sents:\n",
    "        found_subject = False\n",
    "        for token in sent:\n",
    "            # print(f\"{token},{token.dep_}\")\n",
    "            if token.dep_ in ['nsubj', 'nsubjpass'] and token.ent_kb_id_:\n",
    "                subjects.append(token.ent_kb_id_)\n",
    "                subject_set.add(token.ent_kb_id_)\n",
    "                found_subject = True\n",
    "                break\n",
    "\n",
    "        if not found_subject:\n",
    "            subjects.append(None)\n",
    "    (\"Subjects identified:\", subjects)\n",
    "    \n",
    "    new_doc = preprocessing(final_text)\n",
    "    sentence_forms = []\n",
    "    for sent in new_doc.sents:\n",
    "        entities = [(ent.text, ent.start, ent.end) for ent in sent.ents]\n",
    "        sentence_forms.append(entities)\n",
    "    \n",
    "    # print(\"Entities in each sentence:\", sentence_forms)\n",
    "    \n",
    "    # print(subjects)\n",
    "    \n",
    "    pairs = []\n",
    "    count = 0\n",
    "    for i in range(len(sentence_forms)):\n",
    "        tmp_storage = []\n",
    "        if subjects[i] is not None and len(sentence_forms[i]) > 1:\n",
    "            for entity, ent_start, ent_end in sentence_forms[i]:\n",
    "                check_sub = False\n",
    "                for token in new_doc[ent_start:ent_end]:\n",
    "                    # print(f\"{token} and {token.dep_}\")\n",
    "                    if token.dep_ in ['nsubj', 'nsubjpass']:\n",
    "                        check_sub = True\n",
    "                        break\n",
    "                if check_sub == True:\n",
    "                    continue\n",
    "                tmp_storage.append([subjects[i], entity])\n",
    "                count += 1\n",
    "        pairs.append(tmp_storage)\n",
    "    print(f\"The number of pairs is: {count}\\n\")\n",
    "    \n",
    "    return pairs, final_sents, subject_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Wilhelm Windelband (May 11, 1848 - October 22, 1915) was a German philosopher of the Baden School. Wilhelm Windelband is now mainly remembered for the terms \"nomothetic\" and \"idiographic\", which Wilhelm Windelband introduced. the terms \"nomothetic\" and \"idiographic\", which he introducedhave currency in psychology and other areas, though not necessarily in line with Wilhelm Windelband original meanings. Wilhelm Windelband was a Neo-Kantian who protested other Neo-Kantians of Wilhelm Windelband time and maintained that \"to understand Kant rightly means to go beyond Kant \". Against Wilhelm Windelband positivist contemporaries, Wilhelm Windelband argued that philosophy should engage in humanistic dialogue with the natural sciences rather than uncritically appropriating the natural sciences methodologies. Wilhelm Windelband interests in psychology and cultural sciences represented an opposition to psychologism and historicism schools by a critical philosophic system. Wilhelm Windelband relied in Wilhelm Windelband effort to reach beyond Kant on such philosophers as Georg Wilhelm Friedrich Hegel, Johann Friedrich Herbart, and Hermann Lotze. Closely associated with Wilhelm Windelband was Heinrich Rickert. Wilhelm Windelband disciples were not only noted philosophers, but sociologists like Max Weber and theologians like Ernst Troeltsch and Albert Schweitzer.\"\"\"\n",
    "pairs, final_sents, subject_set = (get_sentence_based_links(text))\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Direct Subject Link Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjects_direct_links(subjects_set):\n",
    "    subject_direct_dict = {}\n",
    "    for subj in subjects_set:\n",
    "        sparql = SPARQLWrapper(\"https://dbpedia.org/sparql\")\n",
    "        sparql.setMethod('POST')  \n",
    "\n",
    "        # Dynamically insert the subject into the query\n",
    "        query_source_to_target = f\"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "        PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "\n",
    "        SELECT DISTINCT ?label\n",
    "        WHERE {{\n",
    "        {{\n",
    "            <{subj}> ?property ?entity .\n",
    "            ?entity rdfs:label ?label .\n",
    "        }} UNION {{\n",
    "            ?entity ?property <{subj}> .\n",
    "            ?entity rdfs:label ?label .\n",
    "        }}\n",
    "        FILTER (lang(?label) = \"en\")\n",
    "        }}\n",
    "        \"\"\"\n",
    "        sparql.setQuery(query_source_to_target)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "\n",
    "        try:\n",
    "            result = sparql.query().convert()\n",
    "            tmp = [item['label']['value'] for item in result[\"results\"][\"bindings\"]]\n",
    "            subject_direct_dict[subj] = model.encode(tmp,show_progress_bar=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Query for {subj} didn't work: {e}\")\n",
    "\n",
    "    return subject_direct_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "result_dict = subjects_direct_links(subject_set)\n",
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"Psychologist\"\n",
    "entity_embedding = model.encode(word)\n",
    "embeddings = result_dict['http://dbpedia.org/resource/Wilhelm_Windelband']\n",
    "cosine_similarities = np.dot(embeddings, entity_embedding)\n",
    "print(np.argmax(cosine_similarities))\n",
    "cosine_similarities[np.argmax(cosine_similarities)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Direct Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_direct_link(source_target):\n",
    "    source_uri, target_uri = source_target\n",
    "    sparql = SPARQLWrapper(\"https://dbpedia.org/sparql\")\n",
    "    sparql.setMethod('POST')  \n",
    "    \n",
    "    query_source_to_target = f\"\"\"\n",
    "    ASK WHERE {{\n",
    "      <{source_uri}> ?p <{target_uri}> .\n",
    "    }}\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query_source_to_target)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    try:\n",
    "        result_source_to_target = sparql.query().convert()\n",
    "        has_link_source_to_target = result_source_to_target['boolean']\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying {source_uri} -> {target_uri}: {e}\")\n",
    "        has_link_source_to_target = False\n",
    "\n",
    "    # Query from target to source\n",
    "    query_target_to_source = f\"\"\"\n",
    "    ASK WHERE {{\n",
    "      <{target_uri}> ?p <{source_uri}> .\n",
    "    }}\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query_target_to_source)\n",
    "\n",
    "    try:\n",
    "        result_target_to_source = sparql.query().convert()\n",
    "        has_link_target_to_source = result_target_to_source['boolean']\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying {target_uri} -> {source_uri}: {e}\")\n",
    "        has_link_target_to_source = False\n",
    "\n",
    "    # Combine the results\n",
    "    has_link = has_link_source_to_target or has_link_target_to_source\n",
    "    return source_uri, target_uri, has_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_direct_link([\"http://dbpedia.org/resource/John_Russell_Reynolds\",\"http://dbpedia.org/resource/Judge\"])[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_linear_version(text):\n",
    "    pairs,final_sents,subject_set = get_sentence_based_links(text)\n",
    "    subject_dict = subjects_direct_links(subject_set)\n",
    "    \n",
    "    if not pairs:\n",
    "        print(\"No entity pairs found here.\")\n",
    "        return 0,[],final_sents\n",
    "    \n",
    "    fractions = []\n",
    "    pair_and_values = []\n",
    "    \n",
    "    for sent_sets in pairs:\n",
    "        score = 0\n",
    "        for pair in sent_sets:\n",
    "            if check_direct_link(pair)[2]:\n",
    "                score+=1\n",
    "                pair_and_values.append([pair[0],pair[1],1])\n",
    "            else:\n",
    "                local_subject= pair[0]\n",
    "                entity_link = pair[1]\n",
    "                last_part = entity_link.split('/')[-1]\n",
    "                entity = last_part.replace('_', ' ')\n",
    "                print(entity)\n",
    "                entity_embeddings = model.encode(entity,show_progress_bar=False)\n",
    "                embeddings = subject_dict[local_subject]\n",
    "                cosine_similarities = np.dot(embeddings, entity_embeddings)\n",
    "                max_similarity = np.max(cosine_similarities)\n",
    "                print(max_similarity)\n",
    "                if max_similarity>0.65:\n",
    "                    score+=1\n",
    "                    pair_and_values.append([pair[0],pair[1],1])\n",
    "                else:\n",
    "                    pair_and_values.append([pair[0],pair[1],0])\n",
    "        if len(sent_sets)==0:\n",
    "            fractions.append(-1)\n",
    "        else:\n",
    "            fractions.append(score/len(sent_sets))\n",
    "    \n",
    "    return fractions, pair_and_values, final_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence_set(args):\n",
    "    index, sent_sets, subject_dict = args\n",
    "    score = 0\n",
    "    local_pair_and_values = []\n",
    "    for pair in sent_sets:\n",
    "        _, _, is_direct = check_direct_link(pair)\n",
    "        if is_direct:\n",
    "            score += 1\n",
    "            local_pair_and_values.append([pair[0], pair[1], 1])\n",
    "        else:\n",
    "            local_subject= pair[0]\n",
    "            entity_link = pair[1]\n",
    "            last_part = entity_link.split('/')[-1]\n",
    "            entity = last_part.replace('_', ' ')\n",
    "            entity_embeddings = model.encode(entity,show_progress_bar=False)\n",
    "            embeddings = subject_dict[local_subject]\n",
    "            \n",
    "            if embeddings.size == 0:\n",
    "                local_pair_and_values.append([pair[0], pair[1], 0])\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            cosine_similarities = np.dot(embeddings, entity_embeddings)\n",
    "            max_similarity = np.max(cosine_similarities)\n",
    "            if max_similarity>0.65:\n",
    "                score+=1\n",
    "                local_pair_and_values.append([pair[0],pair[1],1])\n",
    "            else:\n",
    "                local_pair_and_values.append([pair[0],pair[1],0])\n",
    "    fraction = score / len(sent_sets) if len(sent_sets) > 0 else -1\n",
    "    return index, fraction, local_pair_and_values\n",
    "\n",
    "def scoring_parallel_version(text):\n",
    "    pairs, final_sents, subject_set = get_sentence_based_links(text)\n",
    "    subject_dict = subjects_direct_links(subject_set)\n",
    "\n",
    "    if not pairs:\n",
    "        print(\"No entity pairs found here.\")\n",
    "        return 0, [], final_sents\n",
    "\n",
    "    fractions = [None] * len(pairs)\n",
    "    pair_and_values = [None] * len(pairs)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Prepare the arguments for each task\n",
    "        task_args = [(index, sent_sets, subject_dict) for index, sent_sets in enumerate(pairs)]\n",
    "        # Process each sentence set in parallel\n",
    "        results = list(executor.map(process_sentence_set, task_args))\n",
    "\n",
    "    # Place results back into the correct order\n",
    "    for index, fraction, local_pair_and_values in results:\n",
    "        fractions[index] = fraction\n",
    "        pair_and_values[index] = local_pair_and_values\n",
    "\n",
    "    # Flatten pair_and_values list\n",
    "    flat_pair_and_values = [item for sublist in pair_and_values for item in sublist]\n",
    "\n",
    "    return fractions, flat_pair_and_values, final_sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test =  [\"John Russell Reynolds (1820–1876) was an English lawyer, judge, and author.\", \"He was born in London, the son of a barrister, and was educated at Eton College and Trinity College, Cambridge.\", \"He was called to the bar in 1845, and became a Queen's Counsel in 1859.\", \"He was appointed a judge of the Court of Common Pleas in 1867, and was knighted in 1871.\", \"Reynolds was a prolific author, writing on a wide range of topics.\", \"He wrote several books on legal topics, including The Law of Libel and Slander (1863), The Law of Copyright (1865), and The Law of Patents for Inventions (1868).\", \"He also wrote on a variety of other topics, including history, biography, and literature.\", \"He was a frequent contributor to the Saturday Review, and wrote several books on Shakespeare, including The Mystery of William Shakespeare (1848) and The Authorship of Shakespeare (1875).\", \"He also wrote a biography of the poet John Keats (1848).\" ]\n",
    "# test = [ \"Gordon David Strachan (born 9 February 1957) is a Scottish football manager and former player.\", \"He is the manager of the Scotland national team.\", \"Strachan played for Dundee, Aberdeen, Manchester United, Leeds United and Coventry City, as well as the Scotland national team.\", \"He has also managed Coventry City, Southampton, Celtic and Middlesbrough.\", \"Strachan began his managerial career at Coventry City in 1996, leading them to the 1997 FA Cup Final, where they lost to Tottenham Hotspur.\", \"He then moved to Southampton in 2001, where he guided them to the 2003 FA Cup Final, which they lost to Arsenal.\", \"In 2005, he was appointed manager of Celtic, where he won three consecutive Scottish Premier League titles and the Scottish League Cup twice.\", \"He left Celtic in 2009 and was appointed manager of Middlesbrough in October 2010.\", \"He left Middlesbrough in October 2013.\", \"In January 2013, Strachan was appointed manager of the Scotland national team.\", \"He has since led Scotland to the UEFA Euro 2016 qualifying playoffs, where they were eliminated by eventual finalists, and to the 2018 FIFA World Cup\" ]\n",
    "# text = \"\"\n",
    "# for i in test:\n",
    "#    text += \" \" + i\n",
    "# print(text)\n",
    "print(scoring_parallel_version(text))\n",
    "\n",
    "# print(end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate = []\n",
    "minor_inaccurate = []\n",
    "major_inaccurate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"Output\"\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "for i in tqdm(range(28,100), desc=\"Processing entries\", unit=\"entry\"):\n",
    "    list_of_sentences = (dataset[\"evaluation\"][i][\"gpt3_sentences\"])\n",
    "    sentences = ''''''\n",
    "    for s in list_of_sentences:\n",
    "        tmp = preprocess_text(s)\n",
    "        if tmp[-1]!='.':\n",
    "            tmp+='.'\n",
    "        sentences = sentences + tmp + \"\\n\" \n",
    "    ground_truth_doc = preprocessing(dataset[\"evaluation\"][i][\"wiki_bio_text\"])\n",
    "    ground_truth = ''''''\n",
    "    for sent in ground_truth_doc.sents:\n",
    "        temp = preprocess_text(sent.text)\n",
    "        if temp[-1]!='.':\n",
    "            temp+='.'\n",
    "        ground_truth = ground_truth + temp + \"\\n\" \n",
    "    annotation = dataset[\"evaluation\"][i][\"annotation\"]\n",
    "    \n",
    "    sentences_scores, sentence_pairs_and_values , sentence_coref_sents= scoring_parallel_version(sentences)\n",
    "    ground_truth_scores, ground_pairs_and_values, ground_coref_sents = scoring_parallel_version(ground_truth)\n",
    "        \n",
    "    filename = os.path.join(folder_name, f\"entry_{i+1}.txt\")\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"#############SENTENCE_PAIRS############\\n\\n\")\n",
    "        for x in range(len(sentence_pairs_and_values)):\n",
    "            file.write(f\"{sentence_pairs_and_values[x][0]} and {sentence_pairs_and_values[x][1]} and the value is : {sentence_pairs_and_values[x][2]}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"#############GROUND_PAIRS############\\n\\n\")\n",
    "        for x in range(len(ground_pairs_and_values)):\n",
    "            file.write(f\"{ground_pairs_and_values[x][0]} and {ground_pairs_and_values[x][1]} and the value is : {ground_pairs_and_values[x][2]}\\n\")\n",
    "        file.write(\"\\n\\n\")\n",
    "        file.write(\"%%%%%%%%%%%%%%%%%%%%SENTENCES%%%%%%%%%%%%%%%%%\\n\")\n",
    "        file.write(f\"Sentences : \\n\\n{sentences}\\n\\n\")\n",
    "        file.write(f\"Coref Resolved: \\n\\n\")\n",
    "        for y,x in enumerate(sentence_coref_sents):\n",
    "            file.write(f\"{y}. {x}\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"%%%%%%%%%%%%%%%%%%%%GROUND_TRUTH%%%%%%%%%%%%%%%\\n\")\n",
    "        file.write(f\"Ground Truth : \\n\\n{ground_truth} \\n\\n\")\n",
    "        file.write(f\"Coref Resolved: \\n\\n\")\n",
    "        for y,x in enumerate(ground_coref_sents):\n",
    "            file.write(f\"{y}. {x}\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"%%%%%%%%%%%%%%%%%%%%FRACTIONS%%%%%%%%%%%%%%%%%%\\n\")\n",
    "        file.write(f\"Value for sentences is : \\n\")\n",
    "        for x in sentences_scores:\n",
    "            file.write(f\"{x} \")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(f\"Value for ground truth is : \\n\")\n",
    "        for x in ground_truth_scores:\n",
    "            file.write(f\"{x} \")\n",
    "        file.write(\"\\n\\n\")\n",
    "        file.write(\"%%%%%%%%%%%%%%%%%%%%ANNOTATIONS%%%%%%%%%%%%%%%%\\n\")\n",
    "        for x in annotation:\n",
    "            file.write(f\"{x} \")\n",
    "        file.write(\"\\n\\n\")\n",
    "        \n",
    "    suma = 0\n",
    "    leng = 0\n",
    "    for x in ground_truth_scores:\n",
    "        if x!=-1:\n",
    "            suma+=x\n",
    "            leng+=1\n",
    "    \n",
    "    if leng>0:\n",
    "        print(f\"The ground truth scores are: {suma/leng}\\n\")\n",
    "\n",
    "    if (leng)>0 and (suma/leng)>0.25:\n",
    "        if len(sentences_scores)!=len(annotation):\n",
    "            continue\n",
    "        for scores in ground_truth_scores:\n",
    "            if scores==-1:\n",
    "                continue\n",
    "            else:\n",
    "                accurate.append(scores)\n",
    "        for t,score in enumerate(sentences_scores):\n",
    "            if score==-1:\n",
    "                continue\n",
    "            if annotation[t-1]==\"accurate\":\n",
    "                accurate.append(score) \n",
    "            elif annotation[t-1]==\"minor_inaccurate\":\n",
    "                minor_inaccurate.append(score)\n",
    "            elif annotation[t-1]==\"major_inaccurate\":\n",
    "                major_inaccurate.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(accurate)/len(accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(minor_inaccurate)/len(minor_inaccurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(minor_inaccurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(major_inaccurate)/len(major_inaccurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(major_inaccurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Traded to the San Diego Chargers, Aldridge played two seasons in San Diego before retiring from professional football in 1973.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = preprocessing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ents in doc.ents:\n",
    "    print(f\"{ents} __ {ents.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import requests\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the sentence\n",
    "sentence = \"Albert Einstein was a theoretical physicist who developed the theory of relativity.\"\n",
    "\n",
    "# Parse the sentence using spaCy\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Extract subjects from the sentence\n",
    "subjects = [token.text for token in doc if token.dep_ == \"nsubj\"]\n",
    "\n",
    "print(\"Extracted Subjects:\", subjects)\n",
    "\n",
    "def link_to_dbpedia(subject):\n",
    "    spotlight_url = \"https://api.dbpedia-spotlight.org/en/annotate\"\n",
    "    headers = {\"accept\": \"application/json\"}\n",
    "    params = {\"text\": subject, \"confidence\": 0.5}\n",
    "\n",
    "    response = requests.get(spotlight_url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'Resources' in data:\n",
    "            resources = data['Resources']\n",
    "            return resources[0]['@URI']\n",
    "    return None\n",
    "\n",
    "# Link each extracted subject to a DBpedia entry\n",
    "for subject in subjects:\n",
    "    dbpedia_uri = link_to_dbpedia(subject)\n",
    "    if dbpedia_uri:\n",
    "        print(f\"Subject: {subject} -> DBpedia URI: {dbpedia_uri}\")\n",
    "    else:\n",
    "        print(f\"Subject: {subject} -> No DBpedia URI found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Based System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipediaapi Doesnt work ->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switched to wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"Produce a list of common words in the english language.\"\n",
    "text = preprocessing(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_compound_subject_span(sent):\n",
    "    compound_subject = []\n",
    "\n",
    "    for i, token in enumerate(sent):\n",
    "        # print(f\"{token} and {token.dep_}\")\n",
    "        if token.dep_ in [\"nsubj\",\"nsubjpass\"]:\n",
    "            compound_subject.append(token.text)\n",
    "            for j in range(i - 1, -1, -1):\n",
    "                if sent[j].dep_ == \"compound\":\n",
    "                    # print(f\"{sent[j]} and {sent[j].dep_}\")\n",
    "                    compound_subject.insert(0, sent[j].text) \n",
    "                else:\n",
    "                    break  \n",
    "            break\n",
    "    if compound_subject == []:\n",
    "        for i, token in enumerate(sent):\n",
    "            # print(f\"{token} and {token.dep_}\")\n",
    "            if token.dep_ in [\"dobj\",\"iobj\",\"pobj\"]:\n",
    "                compound_subject.append(token.text)\n",
    "                for j in range(i - 1, -1, -1):\n",
    "                    if sent[j].dep_ == \"compound\":\n",
    "                        # print(f\"{sent[j]} and {sent[j].dep_}\")\n",
    "                        compound_subject.insert(0, sent[j].text) \n",
    "                    else:\n",
    "                        break  \n",
    "                break\n",
    "\n",
    "    return \" \".join(compound_subject) if compound_subject else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dep_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[228], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mextract_compound_subject_span\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[226], line 6\u001b[0m, in \u001b[0;36mextract_compound_subject_span\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m      2\u001b[0m compound_subject \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sent):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# print(f\"{token} and {token.dep_}\")\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdep_\u001b[49m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnsubj\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnsubjpass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      7\u001b[0m         compound_subject\u001b[38;5;241m.\u001b[39mappend(token\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dep_'"
     ]
    }
   ],
   "source": [
    "extract_compound_subject_span(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:39:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77022dfe2bd4433da3cc46a038b211b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:39:21 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae19a63bd6c4e23b8d2b7834fe19765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windelband\n",
      "Windelband\n",
      "Kant\n",
      "Georg Wilhelm Friedrich Hegel\n",
      "Johann Friedrich Herbart\n",
      "Hermann Lotze\n"
     ]
    }
   ],
   "source": [
    "text =\"\"\"After the family moved to Kilburn, Tommy Nutter and Tommy Nutter brother David attended Willesden Technical College.\"\"\"\n",
    "text = \"\"\"Windelband relied in his effort to reach beyond Kant on such philosophers as Georg Wilhelm Friedrich Hegel, Johann Friedrich Herbart, and Hermann Lotze.\"\"\"\n",
    "\n",
    "text = coreference_resolution(text)\n",
    "input = preprocessing(text)\n",
    "\n",
    "# for token in input:\n",
    "#     print(f\"{token} and {token.dep_}\")\n",
    "# for sent in input.sents:\n",
    "#     print(extract_compound_subject_span(sent))\n",
    "for entities in input.ents:\n",
    "    print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Based Link Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_based_links_wiki(text):\n",
    "    output = {}\n",
    "    \n",
    "    output[\"Initial_Text\"] = text\n",
    "    # print(text)\n",
    "    \n",
    "    t1 = coreference_resolution(text)\n",
    "    final_text = preprocess_text(t1)\n",
    "    \n",
    "    # print(final_text)\n",
    "    output[\"Coref_Resolved_Text\"] = final_text\n",
    "    \n",
    "    doc = nlp(final_text)\n",
    "    \n",
    "    # print([ents for ents in doc.noun_chunks])\n",
    "    \n",
    "    final_sents = [sents for sents in doc.sents]\n",
    "    output[\"Coref_Resolved_Sentences\"] = final_sents \n",
    "    \n",
    "    subjects = []\n",
    "    subject_set = set([])\n",
    "    subjects_with_context = []\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        tmp_subj = extract_compound_subject_span(sent)\n",
    "        subjects.append(tmp_subj)\n",
    "        if tmp_subj!=None:\n",
    "            if tmp_subj not in subject_set:\n",
    "                subject_set.add(tmp_subj)\n",
    "                subjects_with_context.append([tmp_subj,sent.text])\n",
    "\n",
    "    \n",
    "    sentence_forms = []\n",
    "    base_form = []\n",
    "    \n",
    "    # for sent in final_sents:\n",
    "    #     tmp_text = sent.text\n",
    "    #     tmp_text = tmp_text.strip()\n",
    "    #     new_sent = preprocessing(tmp_text)\n",
    "        \n",
    "    #     entities = []\n",
    "    #     for ents in new_sent.noun_chunks:\n",
    "    #         start_idx = ents.start\n",
    "    #         end_idx = ents.end\n",
    "\n",
    "    #         start_context = max(0, start_idx - 5) \n",
    "    #         end_context = min(len(sent), end_idx + 5) \n",
    "\n",
    "    #         context_tokens = sent[start_context:end_context]\n",
    "    #         entity_context = \" \".join(token.text for token in context_tokens)\n",
    "\n",
    "    #         new_text = f\"{ents.text}: {entity_context}\"\n",
    "    #         entities.append(new_text)\n",
    "        \n",
    "    #     sentence_forms.append(entities)\n",
    "        \n",
    "    \n",
    "    for i,sent in enumerate(final_sents):\n",
    "        tmp_text = sent.text\n",
    "        tmp_text = tmp_text.strip()\n",
    "        new_sent = preprocessing(tmp_text)\n",
    "        \n",
    "        entities = []\n",
    "        base_entities = []\n",
    "        for ents in new_sent.noun_chunks:\n",
    "            if ents.text not in subjects:\n",
    "                new_text = f\"{ents.text}\"\n",
    "                entities.append(new_text)\n",
    "                base_entities.append(ents.text)\n",
    "        \n",
    "        sentence_forms.append(entities)\n",
    "        base_form.append(base_entities)\n",
    "    \n",
    "    # print(\"Entities in each sentence:\", sentence_forms)\n",
    "    \n",
    "    output[\"Sentence_wise_Entities\"] = sentence_forms\n",
    "    output[\"Sentence_wise_subjects\"] = subjects\n",
    "    # print(subjects)\n",
    "    \n",
    "    pairs = []\n",
    "    count = 0\n",
    "    for i in range(len(sentence_forms)):\n",
    "        tmp_storage = []\n",
    "        if subjects[i] is not None and len(sentence_forms[i]) > 0:\n",
    "            for j,entity in enumerate(sentence_forms[i]):\n",
    "                tmp_storage.append([subjects[i], entity])\n",
    "                count += 1\n",
    "        pairs.append(tmp_storage)\n",
    "    # print(f\"The number of pairs is: {count}\\n\")\n",
    "    \n",
    "    output[\"Sentence_Wise_pairs\"] = pairs\n",
    "    \n",
    "    return pairs, final_sents, subject_set, subjects_with_context,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:08:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400fafa93fb04bd3b9ba03b2681d21a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:08:22 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227fdbd9e1d24ce79a3e64eb05719f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Wilhelm Windelband', 'May 11, 1848 - October'], ['Wilhelm Windelband', 'a German philosopher'], ['Wilhelm Windelband', 'the Baden School']], [['Wilhelm Windelband', 'the terms'], ['Wilhelm Windelband', 'which'], ['Wilhelm Windelband', 'he']], [['terms', 'the terms'], ['terms', 'which'], ['terms', 'he'], ['terms', 'currency'], ['terms', 'psychology'], ['terms', 'other areas'], ['terms', 'line'], ['terms', 'Wilhelm Windelband original meanings']], [['Wilhelm Windelband', 'a Neo-Kantian'], ['Wilhelm Windelband', 'who'], ['Wilhelm Windelband', 'other Neo-Kantians'], ['Wilhelm Windelband', 'Wilhelm Windelband time'], ['Wilhelm Windelband', 'Kant'], ['Wilhelm Windelband', 'Kant']], [['Wilhelm Windelband', 'Wilhelm Windelband positivist contemporaries'], ['Wilhelm Windelband', 'philosophy'], ['Wilhelm Windelband', 'humanistic dialogue'], ['Wilhelm Windelband', 'the natural sciences'], ['Wilhelm Windelband', 'the natural sciences methodologies']], [['Wilhelm Windelband interests', 'psychology and cultural sciences'], ['Wilhelm Windelband interests', 'an opposition'], ['Wilhelm Windelband interests', 'psychologism'], ['Wilhelm Windelband interests', 'historicism schools'], ['Wilhelm Windelband interests', 'a critical philosophic system']], [['Wilhelm Windelband', 'Wilhelm Windelband effort'], ['Wilhelm Windelband', 'Kant'], ['Wilhelm Windelband', 'such philosophers'], ['Wilhelm Windelband', 'Georg Wilhelm Friedrich Hegel'], ['Wilhelm Windelband', 'Johann Friedrich Herbart'], ['Wilhelm Windelband', 'Hermann Lotze']], [['Wilhelm Windelband', 'Heinrich Rickert']], [['Wilhelm Windelband disciples', 'noted philosophers'], ['Wilhelm Windelband disciples', 'sociologists'], ['Wilhelm Windelband disciples', 'Max Weber'], ['Wilhelm Windelband disciples', 'theologians'], ['Wilhelm Windelband disciples', 'Ernst Troeltsch'], ['Wilhelm Windelband disciples', 'Albert Schweitzer']]]\n",
      "{'Initial_Text': 'Wilhelm Windelband (May 11, 1848 - October 22, 1915) was a German philosopher of the Baden School.\\nWindelband is now mainly remembered for the terms \"nomothetic\" and \"idiographic\", which he introduced.\\nThese have currency in psychology and other areas, though not necessarily in line with his original meanings.\\nWindelband was a Neo-Kantian who protested other Neo-Kantians of his time and maintained that \"to understand Kant rightly means to go beyond him\".\\nAgainst his positivist contemporaries, Windelband argued that philosophy should engage in humanistic dialogue with the natural sciences rather than uncritically appropriating its methodologies.\\nHis interests in psychology and cultural sciences represented an opposition to psychologism and historicism schools by a critical philosophic system.\\nWindelband relied in his effort to reach beyond Kant on such philosophers as Georg Wilhelm Friedrich Hegel, Johann Friedrich Herbart, and Hermann Lotze.\\nClosely associated with Windelband was Heinrich Rickert.\\nWindelband\\'s disciples were not only noted philosophers, but sociologists like Max Weber and theologians like Ernst Troeltsch and Albert Schweitzer.', 'Coref_Resolved_Text': 'Wilhelm Windelband (May 11, 1848 - October 22, 1915) was a German philosopher of the Baden School. Wilhelm Windelband is now mainly remembered for the terms \"nomothetic\" and \"idiographic\", which he introduced . the terms \"nomothetic\" and \"idiographic\", which he introduced have currency in psychology and other areas, though not necessarily in line with Wilhelm Windelband original meanings. Wilhelm Windelband was a Neo-Kantian who protested other Neo-Kantians of Wilhelm Windelband time and maintained that \"to understand Kant rightly means to go beyond Kant \". Against Wilhelm Windelband positivist contemporaries, Wilhelm Windelband argued that philosophy should engage in humanistic dialogue with the natural sciences rather than uncritically appropriating the natural sciences methodologies. Wilhelm Windelband interests in psychology and cultural sciences represented an opposition to psychologism and historicism schools by a critical philosophic system. Wilhelm Windelband relied in Wilhelm Windelband effort to reach beyond Kant on such philosophers as Georg Wilhelm Friedrich Hegel, Johann Friedrich Herbart, and Hermann Lotze. Closely associated with Wilhelm Windelband was Heinrich Rickert. Wilhelm Windelband disciples were not only noted philosophers, but sociologists like Max Weber and theologians like Ernst Troeltsch and Albert Schweitzer.', 'Coref_Resolved_Sentences': [Wilhelm Windelband (May 11, 1848 - October 22, 1915) was a German philosopher of the Baden School., Wilhelm Windelband is now mainly remembered for the terms \"nomothetic\" and \"idiographic\", which he introduced ., the terms \"nomothetic\" and \"idiographic\", which he introduced have currency in psychology and other areas, though not necessarily in line with Wilhelm Windelband original meanings., Wilhelm Windelband was a Neo-Kantian who protested other Neo-Kantians of Wilhelm Windelband time and maintained that \"to understand Kant rightly means to go beyond Kant \"., Against Wilhelm Windelband positivist contemporaries, Wilhelm Windelband argued that philosophy should engage in humanistic dialogue with the natural sciences rather than uncritically appropriating the natural sciences methodologies., Wilhelm Windelband interests in psychology and cultural sciences represented an opposition to psychologism and historicism schools by a critical philosophic system., Wilhelm Windelband relied in Wilhelm Windelband effort to reach beyond Kant on such philosophers as Georg Wilhelm Friedrich Hegel, Johann Friedrich Herbart, and Hermann Lotze., Closely associated with Wilhelm Windelband was Heinrich Rickert., Wilhelm Windelband disciples were not only noted philosophers, but sociologists like Max Weber and theologians like Ernst Troeltsch and Albert Schweitzer.], 'Sentence_wise_Entities': [['May 11, 1848 - October', 'a German philosopher', 'the Baden School'], ['the terms', 'which', 'he'], ['the terms', 'which', 'he', 'currency', 'psychology', 'other areas', 'line', 'Wilhelm Windelband original meanings'], ['a Neo-Kantian', 'who', 'other Neo-Kantians', 'Wilhelm Windelband time', 'Kant', 'Kant'], ['Wilhelm Windelband positivist contemporaries', 'philosophy', 'humanistic dialogue', 'the natural sciences', 'the natural sciences methodologies'], ['psychology and cultural sciences', 'an opposition', 'psychologism', 'historicism schools', 'a critical philosophic system'], ['Wilhelm Windelband effort', 'Kant', 'such philosophers', 'Georg Wilhelm Friedrich Hegel', 'Johann Friedrich Herbart', 'Hermann Lotze'], ['Heinrich Rickert'], ['noted philosophers', 'sociologists', 'Max Weber', 'theologians', 'Ernst Troeltsch', 'Albert Schweitzer']], 'Sentence_wise_subjects': ['Wilhelm Windelband', 'Wilhelm Windelband', 'terms', 'Wilhelm Windelband', 'Wilhelm Windelband', 'Wilhelm Windelband interests', 'Wilhelm Windelband', 'Wilhelm Windelband', 'Wilhelm Windelband disciples'], 'Sentence_Wise_pairs': [[['Wilhelm Windelband', 'May 11, 1848 - October'], ['Wilhelm Windelband', 'a German philosopher'], ['Wilhelm Windelband', 'the Baden School']], [['Wilhelm Windelband', 'the terms'], ['Wilhelm Windelband', 'which'], ['Wilhelm Windelband', 'he']], [['terms', 'the terms'], ['terms', 'which'], ['terms', 'he'], ['terms', 'currency'], ['terms', 'psychology'], ['terms', 'other areas'], ['terms', 'line'], ['terms', 'Wilhelm Windelband original meanings']], [['Wilhelm Windelband', 'a Neo-Kantian'], ['Wilhelm Windelband', 'who'], ['Wilhelm Windelband', 'other Neo-Kantians'], ['Wilhelm Windelband', 'Wilhelm Windelband time'], ['Wilhelm Windelband', 'Kant'], ['Wilhelm Windelband', 'Kant']], [['Wilhelm Windelband', 'Wilhelm Windelband positivist contemporaries'], ['Wilhelm Windelband', 'philosophy'], ['Wilhelm Windelband', 'humanistic dialogue'], ['Wilhelm Windelband', 'the natural sciences'], ['Wilhelm Windelband', 'the natural sciences methodologies']], [['Wilhelm Windelband interests', 'psychology and cultural sciences'], ['Wilhelm Windelband interests', 'an opposition'], ['Wilhelm Windelband interests', 'psychologism'], ['Wilhelm Windelband interests', 'historicism schools'], ['Wilhelm Windelband interests', 'a critical philosophic system']], [['Wilhelm Windelband', 'Wilhelm Windelband effort'], ['Wilhelm Windelband', 'Kant'], ['Wilhelm Windelband', 'such philosophers'], ['Wilhelm Windelband', 'Georg Wilhelm Friedrich Hegel'], ['Wilhelm Windelband', 'Johann Friedrich Herbart'], ['Wilhelm Windelband', 'Hermann Lotze']], [['Wilhelm Windelband', 'Heinrich Rickert']], [['Wilhelm Windelband disciples', 'noted philosophers'], ['Wilhelm Windelband disciples', 'sociologists'], ['Wilhelm Windelband disciples', 'Max Weber'], ['Wilhelm Windelband disciples', 'theologians'], ['Wilhelm Windelband disciples', 'Ernst Troeltsch'], ['Wilhelm Windelband disciples', 'Albert Schweitzer']]]}\n"
     ]
    }
   ],
   "source": [
    "text =\"\"\"Wilhelm Windelband (May 11, 1848 - October 22, 1915) was a German philosopher of the Baden School.\n",
    "Windelband is now mainly remembered for the terms \"nomothetic\" and \"idiographic\", which he introduced.\n",
    "These have currency in psychology and other areas, though not necessarily in line with his original meanings.\n",
    "Windelband was a Neo-Kantian who protested other Neo-Kantians of his time and maintained that \"to understand Kant rightly means to go beyond him\".\n",
    "Against his positivist contemporaries, Windelband argued that philosophy should engage in humanistic dialogue with the natural sciences rather than uncritically appropriating its methodologies.\n",
    "His interests in psychology and cultural sciences represented an opposition to psychologism and historicism schools by a critical philosophic system.\n",
    "Windelband relied in his effort to reach beyond Kant on such philosophers as Georg Wilhelm Friedrich Hegel, Johann Friedrich Herbart, and Hermann Lotze.\n",
    "Closely associated with Windelband was Heinrich Rickert.\n",
    "Windelband's disciples were not only noted philosophers, but sociologists like Max Weber and theologians like Ernst Troeltsch and Albert Schweitzer.\"\"\"\n",
    "\n",
    "pairs, final_sents, subject_set, subjects_with_context,output = (get_sentence_based_links_wiki(text))\n",
    "print(pairs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject Direct Links Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjects_direct_links_wiki(subject_with_context):\n",
    "    \n",
    "    subject_direct_dict = {}\n",
    "    subject_direct_word_dict = {}\n",
    "    \n",
    "    result_set = set([])\n",
    "    result_dict = {}\n",
    "    \n",
    "    for pair in subject_with_context:\n",
    "        subject = pair[0]\n",
    "        context = pair[1]\n",
    "        \n",
    "        try:\n",
    "            subj = subject + \": \" + context\n",
    "            if len(subj) > 290:\n",
    "                subj = subj[:290]  # Truncate to 250 characters if it exceeds 300\n",
    "                # print(f\"Truncated query: {subj}\")\n",
    "            \n",
    "            result = wikipedia.search(subj, results = 1)\n",
    "            if result == []:\n",
    "                result = wikipedia.search(subject, results = 1)\n",
    "            # print(result)\n",
    "            for results in result:\n",
    "                if results in result_set:\n",
    "                    subject_direct_dict[subject] = result_dict[results]\n",
    "                else:\n",
    "                    page = wikipedia.page(results)\n",
    "                    tmp = [link for link in page.links]\n",
    "                    subject_direct_word_dict[subject] = tmp\n",
    "                    subject_direct_dict[subject] = model.encode(tmp,show_progress_bar=False)\n",
    "                    result_set.add(results)\n",
    "                    result_dict[results] = subject_direct_dict[subject]\n",
    "                    \n",
    "            if not result:\n",
    "                subject_direct_word_dict[subject] = []\n",
    "                subject_direct_dict[subject] = np.array([],dtype=\"float32\")\n",
    "        except Exception as e:\n",
    "            print(f\"Query for {subj} didn't work: {e}\")\n",
    "            subject_direct_dict[subject] = np.array([],dtype=\"float32\")\n",
    "\n",
    "    return subject_direct_dict, subject_direct_word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = wikipedia.page(\"Rick Mahler\",auto_suggest=False, redirect=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject Direct Links Fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_with_context(page):\n",
    "    links_with_context = []\n",
    "    for link in page.links:\n",
    "        try:\n",
    "            link_page = wikipedia.page(link, auto_suggest=False, redirect=True)\n",
    "            context = link_page.content.split('\\n')[0]  # Get the first paragraph\n",
    "            links_with_context.append(f\"{link}: {context}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch context for {link}: {e}\")\n",
    "            links_with_context.append(f\"{link}\")\n",
    "    return links_with_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def subjects_direct_links_wiki_fast(subject_with_context):\n",
    "    subject_direct_dict = {}\n",
    "    subject_direct_word_dict = {}\n",
    "    subject_kg_link_dict = {}\n",
    "    result_set = set([])\n",
    "    result_dict = {}\n",
    "    \n",
    "    def process_subject(pair):\n",
    "        subject = pair[0]\n",
    "        context = pair[1]\n",
    "        try:\n",
    "            subj = subject + \": \" + context\n",
    "            if len(subj) > 290:\n",
    "                subj = subj[:290] \n",
    "                # print(f\"Truncated query: {subj}\")\n",
    "            \n",
    "            result = wikipedia.search(subj, results=1)\n",
    "            if result == []:\n",
    "                result = wikipedia.search(subject,results=1)\n",
    "            for results in result:\n",
    "                KG_Link = results\n",
    "                if results in result_set:\n",
    "                    return subject, result_dict[results], [], KG_Link\n",
    "                else:\n",
    "                    page = wikipedia.page(results,auto_suggest=False,redirect=True)\n",
    "                    links = [link for link in page.links]\n",
    "                    return subject, None, links, KG_Link\n",
    "            return subject, None, [], \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"Query for {subj} didn't work: {e}\")\n",
    "            return subject, None, [], \"\"\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_subject, pair) for pair in subject_with_context]\n",
    "        for future in as_completed(futures):\n",
    "            subject, encoded_data, links, KG_Link = future.result()\n",
    "            if encoded_data is not None:\n",
    "                subject_direct_dict[subject] = encoded_data\n",
    "                subject_kg_link_dict[subject] = KG_Link\n",
    "            else:\n",
    "                if links:\n",
    "                    encoded_links = model.encode(links, show_progress_bar=False)\n",
    "                    subject_direct_word_dict[subject] = links\n",
    "                    subject_direct_dict[subject] = encoded_links\n",
    "                    subject_kg_link_dict[subject] = KG_Link\n",
    "                    result_set.add(subject)\n",
    "                    result_dict[subject] = encoded_links\n",
    "                else:\n",
    "                    subject_direct_word_dict[subject] = []\n",
    "                    subject_direct_dict[subject] = np.array([], dtype=\"float32\")\n",
    "                    subject_kg_link_dict[subject] = KG_Link\n",
    "\n",
    "    return subject_direct_dict, subject_direct_word_dict, subject_kg_link_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1984 (advertisement)', '1984 (television commercial)', '20th Century Animation', '22 vs. Earth', '8-bit', 'ABC News (United States)', 'AIM alliance', 'AP English Literature and Composition', \"A Bug's Land\", \"A Bug's Life\", 'A Computer Animated Hand', 'A Spark Story', 'Academy Award for Best Animated Feature', 'Ad Age', 'Ahwahnee Hotel', 'AirPods', 'AirPods Max', 'AirPods Pro', 'AirTag', 'Akamai Technologies', 'Al Eisenstat', 'Al Gore', 'Alan Kay', 'Alex Gorsky', 'Alien Swirling Saucers', 'All-in-one PC', 'All One Farm', 'Allusion', 'Alta Mesa Memorial Park', 'Alternative medicine', 'Alvy Ray Smith', 'American University of Beirut', 'Andrea Jung', 'Andreas Deja', 'Andy Hertzfeld', 'Angela Ahrendts', 'Anika Noni Rose', 'Animation studio', 'Annual meeting', 'Anobit', 'App Store', 'App Store (iOS)', \"Apple's EU tax dispute\", 'Apple.com', 'AppleCare+', 'AppleInsider', 'AppleMasters', 'AppleToo', 'Apple Arcade', 'Apple Authorized Service Provider', 'Apple Books', 'Apple Campus', 'Apple Card', 'Apple Computer', 'Apple Developer', 'Apple Developer Tools', 'Apple Fifth Avenue', 'Apple I', 'Apple ID', 'Apple II', 'Apple II series', 'Apple IMC', 'Apple Inc.', 'Apple Inc. advertising', 'Apple Inc. design motifs', 'Apple Industrial Design Group', 'Apple Infinite Loop campus', 'Apple Lisa', 'Apple Mail', 'Apple Maps', 'Apple Music', 'Apple Music 1', 'Apple Music Festival', 'Apple Music Up Next', 'Apple News', 'Apple One', 'Apple Park', 'Apple Pay', 'Apple Podcasts', 'Apple SIM', 'Apple Store', 'Apple Studios', 'Apple TV', 'Apple TV+', 'Apple TV app', 'Apple University', 'Apple Vision Pro', 'Apple Wallet', 'Apple Watch', 'Apple Worldwide Developers Conference', 'Apple and unions', 'Apple car project', 'Apple certification programs', 'Apple community', 'Apple ecosystem', 'Apple orchard', 'Apple silicon', 'Apple supply chain', 'Application software', 'Arabic language', 'Arcade game', 'Arm (company)', 'Armenians', 'Ars Technica', 'Arthur D. Levinson', 'Arthur Rock', 'Asahi Linux', 'Ashram', 'Associated Press', 'Atari, Inc.', 'Audiobook', 'AuthenTec', 'Autobiography of a Yogi', 'Avant-garde', 'Avie Tevanian', 'BIS Records', 'BURN-E', 'Backdating', 'Backronym', 'Bao (film)', 'Barack Obama', 'Barrie R. Cassileth', 'Bassma Al Jandaly', 'Bay News 9', 'Be Here Now (book)', 'Be Inc.', 'Beach Chair (film test)', 'Beats Electronics', 'Beats Music', 'Beats Pill', 'Becoming Steve Jobs', 'Beddit', 'Bertrand Serlet', 'Bette Midler', 'Big Brother (1984)', 'Bill Atkinson', 'Bill Campbell (business executive)', 'Bill Fernandez', 'Bill Gates', 'Bill Hewlett', 'Billy Crystal', 'Blood pressure', 'Bloomberg Businessweek', 'Bloomberg News', 'Blue box', 'Bo Peep (Toy Story)', 'Bob Iger', 'Bob Mansfield', 'Bonita Granville', 'Bono', 'Bookkeeping', 'Borrowed Time (film)', \"Boundin'\", 'Braeburn Capital', 'Brave (2012 film)', 'Breadboard', 'Breakout (video game)', 'BridgeOS', 'Bruce Horn', 'Bruce Sewell', 'Bud Tribble', 'Budapest', 'Buddhism', 'Buddhism in the West', 'Burrell Smith', 'Burrow (film)', 'Business Insider', 'Business partnership', 'Buzz Lightyear', \"Buzz Lightyear's Space Ranger Spin\", 'Buzz Lightyear of Star Command', 'Buzz Lightyear of Star Command: The Adventure Begins', 'CEO', 'CERN', 'CNET', 'CRC Press', 'Cachexia', 'California Hall of Fame', 'Calligraphy', 'CarPlay', \"Carl's Date\", 'Carrie Fisher', 'Cars (film)', 'Cars (franchise)', 'Cars 2', 'Cars 3', 'Cars Land', 'Cars Quatre Roues Rallye', 'Cars Toons', 'Cars on the Road', 'Carson Van Osten', 'Chairman', 'Chemotherapy', 'Chris Espinosa', 'Chris Lattner', 'Chrisann Brennan', 'Christina Aguilera', 'Ciao Alberto', 'Circle Seven Animation', 'Circuit board', 'Clare of Assisi', 'Claris', 'Classic Mac OS', 'Classroom (Apple)', 'Closed adoption', 'Closed architecture', 'Clothing in India', 'Clyde Geronimi', 'Co-parent', 'Coco (2017 film)', 'Coldplay', 'Commodore 64', 'Compressor (software)', 'Computer-animated', 'Computer Animation Production System', 'Computer History Museum', 'Computer mouse', 'Computer platform', 'Computer recycling', 'Computer technician', 'Condé Nast', 'Core Foundation', 'Counterculture of the 1960s', 'Craig Federighi', 'Creativity, Inc.', 'Criticism of Apple Inc.', 'Crown Publishing Group', \"Crush's Coaster\", 'Cue (search engine)', 'Cupertino, California', 'Cupertino Union School District', 'Cyberdog', 'DNA paternity testing', 'Dan Riccio', 'Daniel Kottke', 'Danny Elfman', 'Darwin (operating system)', 'Dash Parr', 'David Gorski', 'David Nagel', 'Day & Night (2010 film)', 'De Anza College', \"Deirdre O'Brien\", 'Del Yocam', 'Delano Lewis', 'Dell, Inc.', 'Designed by Apple in California', 'Desktop publishing', 'DiDi', 'Diane Sawyer', 'Dick Clark', 'Diet for a Small Planet', 'Digital Ocean', 'Digital signal processor', 'Discogs', 'Disney', 'Disney Infinity', 'Disney Legend', 'Disney Legends', 'Disneyland', 'Dock (macOS)', 'Dominic Giampaolo', 'Don Norman', 'Dory (Finding Nemo)', 'Dow Jones & Company', \"Dug's Special Mission\", 'Dug Days', 'Dylan Thomas', 'Dystopia', 'E-waste', 'EE Times', 'Ectopic pregnancy', 'Ed Wynn', 'Eddy Cue', 'Edgar S. Woolard Jr.', 'Edison Awards', 'EditGrid', 'Edna Mode', 'Edwin Catmull', 'Edwin H. Land', 'Eihei-ji', 'Elastigirl', 'Elemental (2023 film)', 'Elio (film)', 'Ellen Hancock', 'Emagic', 'Engadget', 'Environmental practices of Apple', 'Epic Games v. Apple', 'Eric Schmidt', 'Ernest Hemingway', 'Esquire (magazine)', 'Ethernet', 'Eugene, Oregon', 'Eve Jobs', 'Expansion slot', 'Exploring the Reef with Jean-Michel Cousteau', 'Eyvind Earle', 'FBI', 'FBI–Apple encryption dispute', 'FaceTime', 'FileMaker', 'Final Cut Pro', 'Final Cut Pro X', 'Find My', 'Finding Dory', 'Finding Nemo', 'Finding Nemo (franchise)', 'Finding Nemo Submarine Voyage', 'FingerWorks', 'Fitness (Apple)', 'Flags and Waves', 'Float (2019 film)', 'Floppy disk', 'Floyd Norman', 'For the Birds (film)', 'Forbes', 'Forky Asks a Question', 'Fortune (magazine)', 'Fred D. Anderson', 'Game Center', 'Games of Pixar Pier', 'Gap Inc.', 'GarageBand', 'Garry Marshall', 'Gartner', 'Gary Snyder', 'Gawker', 'Genius Bar', 'George Bodenheimer', 'George Crow', 'George Lucas', 'George Orwell', 'George and A.J.', \"Geri's Game\", 'Get a Mac', 'Gil Amelio', 'Gina Smith (author)', 'Glass ceiling', 'Glen Keane', 'Grammy Trustees Award', 'Graphical user interface', 'Green Bay, Wisconsin', 'Greg Joswiak', 'Guerrino De Luca', 'Guru', 'Guy Kawasaki', 'Guy Williams (actor)', 'HP-65', 'Haidakhan Babaji', 'Half-staff', 'Half Dome', 'Hans Zimmer', 'Hasui Kawase', 'Hewlett-Packard', 'High-Tech Employee Antitrust Litigation', 'Hippie trail', 'History of Apple', 'History of Apple Inc.', 'History of bottle recycling in the United States', 'History of the hippie movement', 'History of the iPhone', 'HomeKit', 'HomePod', 'HomePod Mini', 'Home computer', 'Homebrew Computer Club', 'Homestead High School (Cupertino, California)', 'Hormone imbalance', 'Howard Vollum Award', 'I. M. Pei', 'IAd', 'IBM PC compatible', 'IBM Personal Computer', 'IChat', 'ICloud', 'ICon', 'ICon: Steve Jobs', 'IFund', 'ILife', 'IMDb (identifier)', 'IMac', 'IMac G3', 'IMac Pro', 'IMessage', 'IMovie', 'IOS', 'IOS app approvals', 'IOS version history', 'IPad', 'IPadOS', 'IPadOS version history', 'IPad (1st generation)', 'IPad 2', 'IPad Air', 'IPad Mini', 'IPad Pro', 'IPhone', 'IPhone (1st generation)', 'IPhone 3G', 'IPhone 3GS', 'IPhone 4', 'IPhone 4s', 'IPhone hardware', 'IPhoto', 'IPod', 'IPodLinux', 'IPod Classic', 'IPod Mini', 'IPod Nano', 'IPod Shuffle', 'IPod Touch', 'IPod advertising', 'ISBN (identifier)', 'ISSN (identifier)', 'ISteve', 'ITunes', 'ITunes Connect', 'ITunes Radio', 'ITunes Store', 'IWork', 'IWoz: Computer Geek to Cult Icon: How I Invented the Personal Computer, Co-Founded Apple, and Had Fun Doing It', 'Ike Nassi', 'Imagination Technologies', 'InVisage Technologies', 'Inc. (magazine)', 'Incredibles 2', 'Incredicoaster', 'Industrial Light & Magic', 'Industrial design', 'InformationWeek', 'Inside Out (2015 film)', 'Inside Out (franchise)', 'Inside Out 2', 'Integrative medicine', 'Intel', 'Interface Builder', 'International Society for Krishna Consciousness', 'Intrinsity', 'Isabel Ge Mahe', 'Issey Miyake', \"It's Tough to Be a Bug!\", 'Jack-Jack Attack', 'Jack Kirby', 'Jack Wrather', 'Jackling House', 'James A. Bell', 'James Earl Jones', 'Japan', 'Jazz', 'Jean-Louis Gassée', 'Jef Raskin', 'Jeff Williams (Apple)', 'Jefferson Awards for Public Service', 'Jerry Brown', 'Jerry York (businessman)', \"Jessie's Critter Carousel\", 'Jessie (Toy Story)', 'Jewish Action', 'Jim Henson', 'Jim Morris (film producer)', 'Joan Baez', 'Joanna Hoffman', 'Jobs (film)', 'Jodi Benson', 'Joe Biden', 'Joe Namath', 'John Browett', 'John Giannandrea', 'John Goodman', 'John Lasseter', 'John Markoff', 'John Muir', 'John Patrick Crecine', 'John Sculley', 'John Ternus', 'John Wiley & Sons', 'Johnny Depp', 'Johny Srouji', 'Jon Favreau', 'Jon Rubinstein', 'Jonathan Ive', 'Jony Ive', 'Joy (Inside Out)', 'Julie Taymor', 'KOKI-TV', 'Kaleida Labs', 'Katherine L. Adams', 'Kenny Ortega', 'Keynote (presentation software)', 'King Lear', 'Kingdom Hearts III', 'Kitbull', 'Knick Knack', 'Kobun Chino Otogawa', 'Kōbun Chino Otogawa', 'LSD', 'La Luna (2011 film)', 'Lala (website)', 'Lanyard', 'Larry Ellison', 'Larry Tesler', 'LaserWriter', 'Laser printer', 'Laurene Jobs', 'Laurene Powell Jobs', 'Lava (2014 film)', 'Lea Salonga', \"Levi's\", 'Lifted (2006 film)', 'Lightning McQueen', \"Lightning McQueen's Racing Academy\", 'Lightyear (film)', 'Linda Larkin', 'Linux on Apple devices', 'Lisa Brennan-Jobs', 'Lisa P. Jackson', 'List of Apple Computer CEOs', 'List of Apple Inc. media events', 'List of Apple TV+ original programming', 'List of Apple codenames', 'List of Apple operating systems', 'List of Cars characters', 'List of Monsters, Inc. characters', 'List of Pixar awards and nominations', 'List of Pixar awards and nominations (feature films)', 'List of Pixar awards and nominations (short films)', 'List of Pixar film references', 'List of Pixar films', 'List of Pixar shorts', 'List of Pixar staff', 'List of The Incredibles characters', 'List of Toy Story characters', 'List of depictions of Steve Jobs', 'List of iPad accessories', 'List of iPad models', 'List of iPhone models', 'List of mergers and acquisitions by Apple', 'Litigation involving Apple Inc.', 'Liver transplantation', 'Logic Pro', 'Look Around (Apple)', 'Loop (2020 film)', 'Los Altos, California', 'Los Angeles Times', 'Los Gatos, California', 'Lou (2017 film)', 'Louise M. Davies Symphony Hall', 'Luca (2021 film)', 'Luca Maestri', 'Lucasfilm', 'Lucasfilm Animation', \"Luigi's Flying Tires\", \"Luigi's Rollickin' Roadsters\", 'Lutheran', 'Luxo Jr.', 'Luxo Jr. (character)', 'Lysergic acid diethylamide', 'MLS Season Pass', 'MSN', 'MacBook', 'MacBook Air', 'MacBook Pro', 'MacOS', 'MacOS Server', 'MacOS version history', 'MacWorld', 'MacWorld Conference & Expo', 'Mac (computer)', 'Mac App Store', 'Mac Mini', 'Mac OS X', 'Mac OS X 10.0', 'Mac Pro', 'Mac Studio', 'Mach kernel', 'Machinist', 'Macintosh', 'Macintosh 128K', 'Macintosh XL', 'Macintosh clones', 'Macworld Conference & Expo', 'Macworld Conference and Expo', 'MainStage (software)', 'Make Something Wonderful', 'Malek Jandali', 'Manuel Gonzales', 'Mark Hamill', 'Mark Papermaster', 'Mark Twain', 'Market capitalization', 'Marketing of Apple Inc.', 'Mater and the Ghostlight', 'Mechanic', 'Media player software', 'Memorial Sloan Kettering Cancer Center', 'Memphis, Tennessee', 'Menlo Park, California', 'Merida (Brave)', 'Messages (Apple)', 'Metaio', 'Methodist University Hospital', 'Michael Dell', 'Michael Eisner', 'Michael Moritz', 'Michael Scott (Apple)', 'Michael Spindler', 'Mickey Drexler', 'Microcomputer', 'Microsoft', 'Microsoft Windows', \"Mike's New Car\", 'Mike Markkula', 'Mike Wazowski', 'Ming-Na Wen', 'Mink farm', 'Minyanville', 'MobileMe', 'Moby Dick', 'Mock turtleneck', 'Modem', 'Mona Simpson', 'Monsters, Inc.', 'Monsters, Inc. (franchise)', 'Monsters, Inc. Ride & Go Seek', 'Monsters University', 'Monsters at Work', 'Monta Loma, Mountain View', 'Motion (software)', 'Mountain View, California', 'Mr. Incredible', 'Mr. Incredible and Pals', 'Multi-touch', 'Music (app)', 'Muslim', 'NARA', 'NHK World-Japan', 'Nancy R. Heinen', 'National Medal of Technology', 'National Semiconductor', 'NeXT', 'NeXTMail', 'NeXTSTEP', 'NeXT Computer', 'NeXT Introduction', 'NeXT Laser Printer', 'NeXT MegaPixel Display', 'NeXTcube', 'NeXTcube Turbo', 'NeXTdimension', 'NeXTstation', 'Neem Karoli Baba', 'Nemo & Friends SeaRider', 'Network World', 'New Balance', 'New York Institute of Technology Computer Graphics Lab', 'Newsstand (software)', 'Newton (platform)', 'Nineteen Eighty-Four', 'No Starch Press', 'Nolan Bushnell', 'Nona (2021 film)', 'Nonsectarian', 'Norah Jones', 'Nothing Real', 'Numbers (spreadsheet)', 'OCLC (identifier)', 'Obituary', 'Object-oriented', 'Omar Sharif', 'One Man Band (film)', 'One to One (Apple)', 'Onward (film)', 'OpenDoc', 'OpenStep', 'Open access', 'Open architecture', 'Operating system', 'Oprah Winfrey', 'Oregon', 'Out (2020 film)', 'Outline of Apple Inc.', 'Oval Office', 'P.A. Semi', 'PARC user interface', 'PC Magazine', 'PC Week', 'Pablo Picasso', 'Pacific Time Zone', 'Pages (word processor)', \"Paige O'Hara\", 'Palo Alto, California', 'Pancreas', 'Pancreatic cancer', 'Pancreatic neuroendocrine tumor', 'Pancreaticoduodenectomy', 'Paramahansa Yogananda', 'Partly Cloudy', 'Party Central', 'Paul Deneve', 'Paul Terrell', 'Penguin Books', 'Pepsi-Cola', 'Personal computer', 'Personal computer revolution', 'Pete Docter', 'Peter Oppenheimer', 'Phil Schiller', 'Philip W. Schiller', 'Photos (Apple)', 'Piper (film)', 'Pirates of Silicon Valley', 'Pixar', 'Pixar Canada', 'Pixar Image Computer', 'Pixar Pal-A-Round', 'Pixar Photoscience Team', 'Pixar Pier', 'Pixar RenderMan', 'Pixar Short Films Collection, Volume 1', 'Pixar Short Films Collection, Volume 2', 'Pixar Short Films Collection, Volume 3', 'Planes: Fire & Rescue', 'Planes (film)', 'Plato', 'Podcast', 'Polaroid Corporation', 'Political science', 'Pong', 'Portland, Oregon', 'PostScript', 'Posthumous award', 'Potential acquisition of Disney by Apple', 'PowerBook G4', 'Power Computing Corporation', 'Power to the people (slogan)', 'Pre-installed iOS apps', 'Presidential Medal of Freedom', 'Presto (animation software)', 'Presto (film)', 'PrimeSense', 'Printed circuit board', 'ProCare', 'Product Red', 'Psychedelic drug', 'Purl (film)', 'QuickTime', 'RC Racer', 'Radiation therapy', 'Radiator Springs Racers', 'Randy Wigginton', 'Ratatouille (film)', 'Raymond Watson', 'Reality distortion field', \"Red's Dream\", 'Reed College', 'Reed Jobs', 'Regis McKenna', 'Regis Philbin', 'Relapse', \"Remy's Ratatouille Adventure\", 'Repossession', 'Respiratory arrest', 'Retreat (spiritual)', 'Rich Page', 'Richard Alpert', 'Richard Sapper', 'Ridley Scott', 'Right to repair', \"Riley's First Date?\", 'Ringtone', 'Robert Downey Jr.', 'Robert Friedland', 'Robert Palladino', 'Robin Roberts (newscaster)', 'Rockstar Consortium', 'Rod Holt', 'Rolling Stone', 'Rolling Stone Magazine', 'Ron Johnson (businessman)', 'Ronald Reagan', 'Ronald Sugar', 'Ronald Wayne', 'Ross Perot', 'Roy E. Disney', 'Rush: A Disney–Pixar Adventure', 'Sabih Khan', 'Sacramento, California', 'Safari (web browser)', 'Sally Carrera', 'San Francisco', 'San Francisco, California', 'San Francisco Chronicle', 'San Jose, California', \"Sanjay's Super Team\", 'Satjiv S. Chahil', 'Scott Foresman', 'Scott Forstall', 'Scott McNealy', 'Self (film)', 'Seva Foundation', 'Shazam (music app)', 'Sign in with Apple', 'Silicon Valley', 'Simon & Schuster', 'Sina Tamaddon', 'Siri', 'Sleeveless shirt', 'Slinky Dog Dash', 'Slinky Dog Zigzag Spin', 'Small Fry (book)', 'Smash and Grab (2019 film)', 'Smithsonian Institution', 'Snopes.com', 'Soul (2020 film)', 'Sound recording and reproduction', 'SparkShorts', \"St. Martin's Press\", 'Stan Lee', 'Stanford Graduate School of Business', 'Stanford University', 'Starling (film)', 'Steve Capps', 'Steve Jobs: The Lost Interview', 'Steve Jobs: The Man in the Machine', 'Steve Jobs (book)', 'Steve Jobs (disambiguation)', 'Steve Jobs (film)', 'Steve Jobs Theater', 'Steve Wozniak', 'Steven L. Kent', 'Steven Levy', 'Stevenote', 'Student government president', 'Sun Microsystems', 'Super Bowl', 'Super Bowl XVIII', 'Susan Barnes (computing)', 'Susan Kare', 'Susan Lucci', 'Susan Wagner', 'Swift (programming language)', 'Swiss people', 'Syrians', 'Sōtō', 'Tablet computer', 'Taligent', 'Tassajara Zen Mountain Center', 'TestFlight', 'Texture (app)', 'The (R)evolution of Steve Jobs', 'The Adventures of André & Wally B.', 'The Bite in the Apple', 'The Blue Umbrella (2013 film)', 'The California Museum for History, Women and the Arts', 'The Dam Keeper', 'The Giving Pledge', 'The Good Dinosaur', 'The Incredibles', 'The Incredibles (franchise)', 'The Keyboard Company', \"The Legend of Mor'du\", 'The Little Kingdom', 'The Lost Father', 'The New York Times', 'The Pixar Story', 'The Register', 'The San Remo', 'The Seas with Nemo & Friends', 'The Second Coming of Steve Jobs', 'The Shadow King (film)', 'The Son of a Migrant from Syria', 'The Ultimate History of Video Games', 'The Verge', 'The Walt Disney Company', 'The Washington Post', 'The Works (film)', 'Think different', 'Thoughts on Flash', 'Tim Berners-Lee', 'Tim Cook', 'Time (magazine)', 'Time 100', 'Time Person of the Year', 'Timeline of Apple Inc. products', 'Timeline of Steve Jobs media', 'Timothy Leary', 'Tin Toy', 'Tiny Toy Stories', 'Tony Baxter', 'Tony Fadell', 'Topsy Labs', 'Tow Mater', 'Toy Soldiers Parachute Drop', 'Toy Story', 'Toy Story (franchise)', 'Toy Story 2', 'Toy Story 3', 'Toy Story 4', 'Toy Story Land', 'Toy Story Mania!', 'Toy Story That Time Forgot', 'Toy Story Toons', 'Toy Story of Terror!', 'Transistor–transistor logic', 'Transworld Publishers Limited', 'Triumph of the Nerds', 'Turning Red', 'Turtle Talk with Crush', 'TvOS', 'Twenty Something (2021 film)', 'Typeface', 'Typography of Apple Inc.', 'USB', 'United States Coast Guard', 'United States v. Apple (2012)', 'United States v. Apple (2024)', 'University of California, Berkeley', 'University of Wisconsin', 'Unmarked grave', 'Up (2009 film)', 'User interface', 'Vanity Fair (magazine)', 'Vector graphics', 'Venus (yacht)', 'Violet Parr', 'Virtual keyboard', 'VisionOS', 'Visual effects', 'Volkswagen Type 2', 'W. W. Norton & Company', 'WALL-E', 'WALL-E (character)', 'WWDC', 'Walkie-Talkie (Apple)', 'Walt Disney Animation Studios', 'Walt Disney Studios (division)', 'Walt Disney World', 'Walter Isaacson', 'Warren Buffett', 'Washington County, Wisconsin', 'WatchOS', 'Wayback Machine', 'Wayne Gretzky', 'WebObjects', 'Web browser', 'Weekends (2017 film)', 'Wendell Brown', 'West Coast Computer Faire', 'Whitehouse.gov', 'Whoopi Goldberg', 'Wi-Fi', 'William Campbell (business executive)', 'William Shakespeare', 'Win or Lose (TV series)', 'Wind (2019 film)', 'Wing T. Chao', 'Wired News', 'Woody (Toy Story)', 'Workstation', 'WorldWideWeb', 'World Wide Web', 'Worldwide Developers Conference', 'Xcode', 'Xerox Alto', 'Yo-Yo Ma', 'Yosemite National Park', 'YouTube', 'YouTube video (identifier)', 'Your Friend the Rat', 'ZDnet', 'Zen']\n"
     ]
    }
   ],
   "source": [
    "search_term = \"Steve Jobs\"\n",
    "page = wikipedia.page((wikipedia.search(search_term,results=1))[0],auto_suggest=False,redirect=True)\n",
    "print([links for links in page.links])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WikipediaPage 'Steve Jobs'>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Wilhelm Windelband',\n",
       "  'Wilhelm Windelband (May 11, 1848 - October 22, 1915) was a German philosopher of the Baden School.'],\n",
       " ['terms',\n",
       "  'the terms \"nomothetic\" and \"idiographic\", which he introduced have currency in psychology and other areas, though not necessarily in line with Wilhelm Windelband original meanings.'],\n",
       " ['Wilhelm Windelband interests',\n",
       "  'Wilhelm Windelband interests in psychology and cultural sciences represented an opposition to psychologism and historicism schools by a critical philosophic system.'],\n",
       " ['Wilhelm Windelband disciples',\n",
       "  'Wilhelm Windelband disciples were not only noted philosophers, but sociologists like Max Weber and theologians like Ernst Troeltsch and Albert Schweitzer.']]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_with_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Wilhelm Windelband': array([[ 0.0129078 ,  0.07744548,  0.02033362, ...,  0.02409213,\n",
       "           0.02910504,  0.00767747],\n",
       "         [-0.01241453, -0.00914223, -0.00579345, ...,  0.02605269,\n",
       "           0.01314212, -0.00260564],\n",
       "         [ 0.03970159,  0.02328221,  0.01568113, ..., -0.03660033,\n",
       "           0.03326635,  0.00548261],\n",
       "         ...,\n",
       "         [ 0.02180419,  0.06057727,  0.00269464, ...,  0.01583836,\n",
       "           0.01757044,  0.00485697],\n",
       "         [ 0.03798955,  0.08162113,  0.00288995, ...,  0.01411823,\n",
       "           0.03410124, -0.03442033],\n",
       "         [ 0.02450549,  0.07101952,  0.01709009, ...,  0.01251805,\n",
       "          -0.01737141, -0.02389679]], dtype=float32),\n",
       "  'terms': array([[ 0.0129078 ,  0.07744548,  0.02033362, ...,  0.02409213,\n",
       "           0.02910504,  0.00767747],\n",
       "         [-0.01241453, -0.00914223, -0.00579345, ...,  0.02605269,\n",
       "           0.01314212, -0.00260564],\n",
       "         [ 0.03970159,  0.02328221,  0.01568113, ..., -0.03660033,\n",
       "           0.03326635,  0.00548261],\n",
       "         ...,\n",
       "         [ 0.02180419,  0.06057727,  0.00269464, ...,  0.01583836,\n",
       "           0.01757044,  0.00485697],\n",
       "         [ 0.03798955,  0.08162113,  0.00288995, ...,  0.01411823,\n",
       "           0.03410124, -0.03442033],\n",
       "         [ 0.02450549,  0.07101952,  0.01709009, ...,  0.01251805,\n",
       "          -0.01737141, -0.02389679]], dtype=float32),\n",
       "  'Wilhelm Windelband interests': array([[ 0.0129078 ,  0.07744548,  0.02033362, ...,  0.02409213,\n",
       "           0.02910504,  0.00767747],\n",
       "         [-0.01241453, -0.00914223, -0.00579345, ...,  0.02605269,\n",
       "           0.01314212, -0.00260564],\n",
       "         [ 0.03970159,  0.02328221,  0.01568113, ..., -0.03660033,\n",
       "           0.03326635,  0.00548261],\n",
       "         ...,\n",
       "         [ 0.02180419,  0.06057727,  0.00269464, ...,  0.01583836,\n",
       "           0.01757044,  0.00485697],\n",
       "         [ 0.03798955,  0.08162113,  0.00288995, ...,  0.01411823,\n",
       "           0.03410124, -0.03442033],\n",
       "         [ 0.02450549,  0.07101952,  0.01709009, ...,  0.01251805,\n",
       "          -0.01737141, -0.02389679]], dtype=float32),\n",
       "  'Wilhelm Windelband disciples': array([[ 0.0129078 ,  0.07744548,  0.02033362, ...,  0.02409213,\n",
       "           0.02910504,  0.00767747],\n",
       "         [-0.01241453, -0.00914223, -0.00579345, ...,  0.02605269,\n",
       "           0.01314212, -0.00260564],\n",
       "         [ 0.03970159,  0.02328221,  0.01568113, ..., -0.03660033,\n",
       "           0.03326635,  0.00548261],\n",
       "         ...,\n",
       "         [ 0.02180419,  0.06057727,  0.00269464, ...,  0.01583836,\n",
       "           0.01757044,  0.00485697],\n",
       "         [ 0.03798955,  0.08162113,  0.00288995, ...,  0.01411823,\n",
       "           0.03410124, -0.03442033],\n",
       "         [ 0.02450549,  0.07101952,  0.01709009, ...,  0.01251805,\n",
       "          -0.01737141, -0.02389679]], dtype=float32)},\n",
       " {'Wilhelm Windelband': ['19th-century philosophy',\n",
       "   'A priori and a posteriori',\n",
       "   'Albert Schweitzer',\n",
       "   'Alfred North Whitehead',\n",
       "   'Analytic–synthetic distinction',\n",
       "   'Anti-realism',\n",
       "   'Archive.org',\n",
       "   'Auguste Comte',\n",
       "   'Baden School',\n",
       "   'Bas van Fraassen',\n",
       "   'Bertrand Russell',\n",
       "   'C. D. Broad',\n",
       "   'Carl Gustav Hempel',\n",
       "   'Causality',\n",
       "   'Charles Sanders Peirce',\n",
       "   'Coherentism',\n",
       "   'Commensurability (philosophy of science)',\n",
       "   'Confirmation holism',\n",
       "   'Consilience',\n",
       "   'Construct (philosophy)',\n",
       "   'Constructive empiricism',\n",
       "   'Constructive realism',\n",
       "   'Constructivist epistemology',\n",
       "   'Contextualism',\n",
       "   'Conventionalism',\n",
       "   'Creative synthesis',\n",
       "   'Criticism of science',\n",
       "   'David Hume',\n",
       "   'Deductive-nomological model',\n",
       "   'Demarcation problem',\n",
       "   'Descriptive research',\n",
       "   'Determinism',\n",
       "   'Doctoral advisor',\n",
       "   'Empirical evidence',\n",
       "   'Empiricism',\n",
       "   'Epistemological anarchism',\n",
       "   'Epistemology',\n",
       "   'Ernst Troeltsch',\n",
       "   'Evidence-based practice',\n",
       "   'Evolutionism',\n",
       "   'Explanatory power',\n",
       "   'Fact',\n",
       "   'Faith and rationality',\n",
       "   'Fallibilism',\n",
       "   'Falsifiability',\n",
       "   'Feminist method',\n",
       "   'Foundationalism',\n",
       "   'Francis Bacon',\n",
       "   'Frederick C. Beiser',\n",
       "   'Functional contextualism',\n",
       "   'Galileo Galilei',\n",
       "   'Georg Wilhelm Friedrich Hegel',\n",
       "   'German Empire',\n",
       "   'Grand Duchy of Baden',\n",
       "   'Hans Reichenbach',\n",
       "   'Hard and soft science',\n",
       "   'Heidelberg',\n",
       "   'Heinrich Rickert',\n",
       "   'Heinz Heimsoeth',\n",
       "   'Henri Poincaré',\n",
       "   'Hermann Lotze',\n",
       "   'Historicism',\n",
       "   'History and philosophy of science',\n",
       "   'Hypothetico-deductive model',\n",
       "   'Ian Hacking',\n",
       "   'Idiographic',\n",
       "   'Ignoramus et ignorabimus',\n",
       "   'Immanuel Kant',\n",
       "   'Imre Lakatos',\n",
       "   'Index of philosophy of science articles',\n",
       "   'Inductionism',\n",
       "   'Inductive reasoning',\n",
       "   'Inquiry',\n",
       "   'Instrumentalism',\n",
       "   'Intertheoretic reduction',\n",
       "   'Isaac Newton',\n",
       "   'Johann Friedrich Herbart',\n",
       "   'Karl Pearson',\n",
       "   'Karl Popper',\n",
       "   'Kingdom of Prussia',\n",
       "   'Larry Laudan',\n",
       "   'List of philosophers of science',\n",
       "   'List of schools of philosophy',\n",
       "   'Max Weber',\n",
       "   'Metaphysics',\n",
       "   'Michael Polanyi',\n",
       "   'Model-dependent realism',\n",
       "   'Naturalism (philosophy)',\n",
       "   'Nature (philosophy)',\n",
       "   'Neo-Kantianism',\n",
       "   'Nomothetic',\n",
       "   'Nomothetic and idiographic',\n",
       "   'Normative science',\n",
       "   'Objectivity (philosophy)',\n",
       "   'Observation',\n",
       "   'Otto Neurath',\n",
       "   'Paradigm',\n",
       "   'Paul Feyerabend',\n",
       "   'Philosopher',\n",
       "   'Philosophical analysis',\n",
       "   'Philosophical logic',\n",
       "   'Philosophy of archaeology',\n",
       "   'Philosophy of biology',\n",
       "   'Philosophy of chemistry',\n",
       "   'Philosophy of economics',\n",
       "   'Philosophy of geography',\n",
       "   'Philosophy of history',\n",
       "   'Philosophy of linguistics',\n",
       "   'Philosophy of physics',\n",
       "   'Philosophy of psychology',\n",
       "   'Philosophy of science',\n",
       "   'Philosophy of social science',\n",
       "   'Philosophy of space and time',\n",
       "   'Physicalism',\n",
       "   'Pierre Duhem',\n",
       "   'Positivism',\n",
       "   'Positivist',\n",
       "   'Potsdam',\n",
       "   'Pragmatism',\n",
       "   'Problem of induction',\n",
       "   'Protoscience',\n",
       "   'Province of Brandenburg',\n",
       "   'Pseudoscience',\n",
       "   'Psychologism',\n",
       "   'Psychology',\n",
       "   'Rationalism',\n",
       "   'Received view of theories',\n",
       "   'Reductionism',\n",
       "   'Relationship between religion and science',\n",
       "   'Rhetoric of science',\n",
       "   'Roger Bacon',\n",
       "   'Rudolf Carnap',\n",
       "   'Rudolf Steiner',\n",
       "   'Science studies',\n",
       "   'Scientific Revolution',\n",
       "   'Scientific essentialism',\n",
       "   'Scientific evidence',\n",
       "   'Scientific formalism',\n",
       "   'Scientific law',\n",
       "   'Scientific method',\n",
       "   'Scientific pluralism',\n",
       "   'Scientific realism',\n",
       "   'Scientific skepticism',\n",
       "   'Scientific theory',\n",
       "   'Scientism',\n",
       "   'Semantic view of theories',\n",
       "   'Sociologists',\n",
       "   'Sociology of scientific ignorance',\n",
       "   'Sociology of scientific knowledge',\n",
       "   'Structuralism (philosophy of science)',\n",
       "   'Testability',\n",
       "   'Theologians',\n",
       "   'Theory-ladenness',\n",
       "   'Theory choice',\n",
       "   'Thesis',\n",
       "   'Thomas Kuhn',\n",
       "   'Underdetermination',\n",
       "   'Uniformitarianism',\n",
       "   'Unity of science',\n",
       "   'University of Berlin',\n",
       "   'University of Göttingen',\n",
       "   'University of Jena',\n",
       "   'Vitalism',\n",
       "   'Western philosophy',\n",
       "   'Willard Van Orman Quine']})"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_direct_links_wiki(subjects_with_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Wilhelm Windelband interests': array([[ 0.0129078 ,  0.07744548,  0.02033362, ...,  0.02409213,\n",
       "           0.02910504,  0.00767747],\n",
       "         [-0.01241453, -0.00914223, -0.00579345, ...,  0.02605269,\n",
       "           0.01314212, -0.00260564],\n",
       "         [ 0.03970159,  0.02328221,  0.01568113, ..., -0.03660033,\n",
       "           0.03326635,  0.00548261],\n",
       "         ...,\n",
       "         [ 0.02180419,  0.06057727,  0.00269464, ...,  0.01583836,\n",
       "           0.01757044,  0.00485697],\n",
       "         [ 0.03798955,  0.08162113,  0.00288995, ...,  0.01411823,\n",
       "           0.03410124, -0.03442033],\n",
       "         [ 0.02450549,  0.07101952,  0.01709009, ...,  0.01251805,\n",
       "          -0.01737141, -0.02389679]], dtype=float32),\n",
       "  'Wilhelm Windelband disciples': array([[ 0.0129078 ,  0.07744548,  0.02033362, ...,  0.02409213,\n",
       "           0.02910504,  0.00767747],\n",
       "         [-0.01241453, -0.00914223, -0.00579345, ...,  0.02605269,\n",
       "           0.01314212, -0.00260564],\n",
       "         [ 0.03970159,  0.02328221,  0.01568113, ..., -0.03660033,\n",
       "           0.03326635,  0.00548261],\n",
       "         ...,\n",
       "         [ 0.02180419,  0.06057727,  0.00269464, ...,  0.01583836,\n",
       "           0.01757044,  0.00485697],\n",
       "         [ 0.03798955,  0.08162113,  0.00288995, ...,  0.01411823,\n",
       "           0.03410124, -0.03442033],\n",
       "         [ 0.02450549,  0.07101952,  0.01709009, ...,  0.01251805,\n",
       "          -0.01737141, -0.02389679]], dtype=float32),\n",
       "  'terms': array([[ 0.0129078 ,  0.07744548,  0.02033362, ...,  0.02409213,\n",
       "           0.02910504,  0.00767747],\n",
       "         [-0.01241453, -0.00914223, -0.00579345, ...,  0.02605269,\n",
       "           0.01314212, -0.00260564],\n",
       "         [ 0.03970159,  0.02328221,  0.01568113, ..., -0.03660033,\n",
       "           0.03326635,  0.00548261],\n",
       "         ...,\n",
       "         [ 0.02180419,  0.06057727,  0.00269464, ...,  0.01583836,\n",
       "           0.01757044,  0.00485697],\n",
       "         [ 0.03798955,  0.08162113,  0.00288995, ...,  0.01411823,\n",
       "           0.03410124, -0.03442033],\n",
       "         [ 0.02450549,  0.07101952,  0.01709009, ...,  0.01251805,\n",
       "          -0.01737141, -0.02389679]], dtype=float32),\n",
       "  'Wilhelm Windelband': array([[ 0.0129078 ,  0.07744548,  0.02033362, ...,  0.02409213,\n",
       "           0.02910504,  0.00767747],\n",
       "         [-0.01241453, -0.00914223, -0.00579345, ...,  0.02605269,\n",
       "           0.01314212, -0.00260564],\n",
       "         [ 0.03970159,  0.02328221,  0.01568113, ..., -0.03660033,\n",
       "           0.03326635,  0.00548261],\n",
       "         ...,\n",
       "         [ 0.02180419,  0.06057727,  0.00269464, ...,  0.01583836,\n",
       "           0.01757044,  0.00485697],\n",
       "         [ 0.03798955,  0.08162113,  0.00288995, ...,  0.01411823,\n",
       "           0.03410124, -0.03442033],\n",
       "         [ 0.02450549,  0.07101952,  0.01709009, ...,  0.01251805,\n",
       "          -0.01737141, -0.02389679]], dtype=float32)},\n",
       " {'Wilhelm Windelband interests': ['19th-century philosophy',\n",
       "   'A priori and a posteriori',\n",
       "   'Albert Schweitzer',\n",
       "   'Alfred North Whitehead',\n",
       "   'Analytic–synthetic distinction',\n",
       "   'Anti-realism',\n",
       "   'Archive.org',\n",
       "   'Auguste Comte',\n",
       "   'Baden School',\n",
       "   'Bas van Fraassen',\n",
       "   'Bertrand Russell',\n",
       "   'C. D. Broad',\n",
       "   'Carl Gustav Hempel',\n",
       "   'Causality',\n",
       "   'Charles Sanders Peirce',\n",
       "   'Coherentism',\n",
       "   'Commensurability (philosophy of science)',\n",
       "   'Confirmation holism',\n",
       "   'Consilience',\n",
       "   'Construct (philosophy)',\n",
       "   'Constructive empiricism',\n",
       "   'Constructive realism',\n",
       "   'Constructivist epistemology',\n",
       "   'Contextualism',\n",
       "   'Conventionalism',\n",
       "   'Creative synthesis',\n",
       "   'Criticism of science',\n",
       "   'David Hume',\n",
       "   'Deductive-nomological model',\n",
       "   'Demarcation problem',\n",
       "   'Descriptive research',\n",
       "   'Determinism',\n",
       "   'Doctoral advisor',\n",
       "   'Empirical evidence',\n",
       "   'Empiricism',\n",
       "   'Epistemological anarchism',\n",
       "   'Epistemology',\n",
       "   'Ernst Troeltsch',\n",
       "   'Evidence-based practice',\n",
       "   'Evolutionism',\n",
       "   'Explanatory power',\n",
       "   'Fact',\n",
       "   'Faith and rationality',\n",
       "   'Fallibilism',\n",
       "   'Falsifiability',\n",
       "   'Feminist method',\n",
       "   'Foundationalism',\n",
       "   'Francis Bacon',\n",
       "   'Frederick C. Beiser',\n",
       "   'Functional contextualism',\n",
       "   'Galileo Galilei',\n",
       "   'Georg Wilhelm Friedrich Hegel',\n",
       "   'German Empire',\n",
       "   'Grand Duchy of Baden',\n",
       "   'Hans Reichenbach',\n",
       "   'Hard and soft science',\n",
       "   'Heidelberg',\n",
       "   'Heinrich Rickert',\n",
       "   'Heinz Heimsoeth',\n",
       "   'Henri Poincaré',\n",
       "   'Hermann Lotze',\n",
       "   'Historicism',\n",
       "   'History and philosophy of science',\n",
       "   'Hypothetico-deductive model',\n",
       "   'Ian Hacking',\n",
       "   'Idiographic',\n",
       "   'Ignoramus et ignorabimus',\n",
       "   'Immanuel Kant',\n",
       "   'Imre Lakatos',\n",
       "   'Index of philosophy of science articles',\n",
       "   'Inductionism',\n",
       "   'Inductive reasoning',\n",
       "   'Inquiry',\n",
       "   'Instrumentalism',\n",
       "   'Intertheoretic reduction',\n",
       "   'Isaac Newton',\n",
       "   'Johann Friedrich Herbart',\n",
       "   'Karl Pearson',\n",
       "   'Karl Popper',\n",
       "   'Kingdom of Prussia',\n",
       "   'Larry Laudan',\n",
       "   'List of philosophers of science',\n",
       "   'List of schools of philosophy',\n",
       "   'Max Weber',\n",
       "   'Metaphysics',\n",
       "   'Michael Polanyi',\n",
       "   'Model-dependent realism',\n",
       "   'Naturalism (philosophy)',\n",
       "   'Nature (philosophy)',\n",
       "   'Neo-Kantianism',\n",
       "   'Nomothetic',\n",
       "   'Nomothetic and idiographic',\n",
       "   'Normative science',\n",
       "   'Objectivity (philosophy)',\n",
       "   'Observation',\n",
       "   'Otto Neurath',\n",
       "   'Paradigm',\n",
       "   'Paul Feyerabend',\n",
       "   'Philosopher',\n",
       "   'Philosophical analysis',\n",
       "   'Philosophical logic',\n",
       "   'Philosophy of archaeology',\n",
       "   'Philosophy of biology',\n",
       "   'Philosophy of chemistry',\n",
       "   'Philosophy of economics',\n",
       "   'Philosophy of geography',\n",
       "   'Philosophy of history',\n",
       "   'Philosophy of linguistics',\n",
       "   'Philosophy of physics',\n",
       "   'Philosophy of psychology',\n",
       "   'Philosophy of science',\n",
       "   'Philosophy of social science',\n",
       "   'Philosophy of space and time',\n",
       "   'Physicalism',\n",
       "   'Pierre Duhem',\n",
       "   'Positivism',\n",
       "   'Positivist',\n",
       "   'Potsdam',\n",
       "   'Pragmatism',\n",
       "   'Problem of induction',\n",
       "   'Protoscience',\n",
       "   'Province of Brandenburg',\n",
       "   'Pseudoscience',\n",
       "   'Psychologism',\n",
       "   'Psychology',\n",
       "   'Rationalism',\n",
       "   'Received view of theories',\n",
       "   'Reductionism',\n",
       "   'Relationship between religion and science',\n",
       "   'Rhetoric of science',\n",
       "   'Roger Bacon',\n",
       "   'Rudolf Carnap',\n",
       "   'Rudolf Steiner',\n",
       "   'Science studies',\n",
       "   'Scientific Revolution',\n",
       "   'Scientific essentialism',\n",
       "   'Scientific evidence',\n",
       "   'Scientific formalism',\n",
       "   'Scientific law',\n",
       "   'Scientific method',\n",
       "   'Scientific pluralism',\n",
       "   'Scientific realism',\n",
       "   'Scientific skepticism',\n",
       "   'Scientific theory',\n",
       "   'Scientism',\n",
       "   'Semantic view of theories',\n",
       "   'Sociologists',\n",
       "   'Sociology of scientific ignorance',\n",
       "   'Sociology of scientific knowledge',\n",
       "   'Structuralism (philosophy of science)',\n",
       "   'Testability',\n",
       "   'Theologians',\n",
       "   'Theory-ladenness',\n",
       "   'Theory choice',\n",
       "   'Thesis',\n",
       "   'Thomas Kuhn',\n",
       "   'Underdetermination',\n",
       "   'Uniformitarianism',\n",
       "   'Unity of science',\n",
       "   'University of Berlin',\n",
       "   'University of Göttingen',\n",
       "   'University of Jena',\n",
       "   'Vitalism',\n",
       "   'Western philosophy',\n",
       "   'Willard Van Orman Quine'],\n",
       "  'Wilhelm Windelband disciples': ['19th-century philosophy',\n",
       "   'A priori and a posteriori',\n",
       "   'Albert Schweitzer',\n",
       "   'Alfred North Whitehead',\n",
       "   'Analytic–synthetic distinction',\n",
       "   'Anti-realism',\n",
       "   'Archive.org',\n",
       "   'Auguste Comte',\n",
       "   'Baden School',\n",
       "   'Bas van Fraassen',\n",
       "   'Bertrand Russell',\n",
       "   'C. D. Broad',\n",
       "   'Carl Gustav Hempel',\n",
       "   'Causality',\n",
       "   'Charles Sanders Peirce',\n",
       "   'Coherentism',\n",
       "   'Commensurability (philosophy of science)',\n",
       "   'Confirmation holism',\n",
       "   'Consilience',\n",
       "   'Construct (philosophy)',\n",
       "   'Constructive empiricism',\n",
       "   'Constructive realism',\n",
       "   'Constructivist epistemology',\n",
       "   'Contextualism',\n",
       "   'Conventionalism',\n",
       "   'Creative synthesis',\n",
       "   'Criticism of science',\n",
       "   'David Hume',\n",
       "   'Deductive-nomological model',\n",
       "   'Demarcation problem',\n",
       "   'Descriptive research',\n",
       "   'Determinism',\n",
       "   'Doctoral advisor',\n",
       "   'Empirical evidence',\n",
       "   'Empiricism',\n",
       "   'Epistemological anarchism',\n",
       "   'Epistemology',\n",
       "   'Ernst Troeltsch',\n",
       "   'Evidence-based practice',\n",
       "   'Evolutionism',\n",
       "   'Explanatory power',\n",
       "   'Fact',\n",
       "   'Faith and rationality',\n",
       "   'Fallibilism',\n",
       "   'Falsifiability',\n",
       "   'Feminist method',\n",
       "   'Foundationalism',\n",
       "   'Francis Bacon',\n",
       "   'Frederick C. Beiser',\n",
       "   'Functional contextualism',\n",
       "   'Galileo Galilei',\n",
       "   'Georg Wilhelm Friedrich Hegel',\n",
       "   'German Empire',\n",
       "   'Grand Duchy of Baden',\n",
       "   'Hans Reichenbach',\n",
       "   'Hard and soft science',\n",
       "   'Heidelberg',\n",
       "   'Heinrich Rickert',\n",
       "   'Heinz Heimsoeth',\n",
       "   'Henri Poincaré',\n",
       "   'Hermann Lotze',\n",
       "   'Historicism',\n",
       "   'History and philosophy of science',\n",
       "   'Hypothetico-deductive model',\n",
       "   'Ian Hacking',\n",
       "   'Idiographic',\n",
       "   'Ignoramus et ignorabimus',\n",
       "   'Immanuel Kant',\n",
       "   'Imre Lakatos',\n",
       "   'Index of philosophy of science articles',\n",
       "   'Inductionism',\n",
       "   'Inductive reasoning',\n",
       "   'Inquiry',\n",
       "   'Instrumentalism',\n",
       "   'Intertheoretic reduction',\n",
       "   'Isaac Newton',\n",
       "   'Johann Friedrich Herbart',\n",
       "   'Karl Pearson',\n",
       "   'Karl Popper',\n",
       "   'Kingdom of Prussia',\n",
       "   'Larry Laudan',\n",
       "   'List of philosophers of science',\n",
       "   'List of schools of philosophy',\n",
       "   'Max Weber',\n",
       "   'Metaphysics',\n",
       "   'Michael Polanyi',\n",
       "   'Model-dependent realism',\n",
       "   'Naturalism (philosophy)',\n",
       "   'Nature (philosophy)',\n",
       "   'Neo-Kantianism',\n",
       "   'Nomothetic',\n",
       "   'Nomothetic and idiographic',\n",
       "   'Normative science',\n",
       "   'Objectivity (philosophy)',\n",
       "   'Observation',\n",
       "   'Otto Neurath',\n",
       "   'Paradigm',\n",
       "   'Paul Feyerabend',\n",
       "   'Philosopher',\n",
       "   'Philosophical analysis',\n",
       "   'Philosophical logic',\n",
       "   'Philosophy of archaeology',\n",
       "   'Philosophy of biology',\n",
       "   'Philosophy of chemistry',\n",
       "   'Philosophy of economics',\n",
       "   'Philosophy of geography',\n",
       "   'Philosophy of history',\n",
       "   'Philosophy of linguistics',\n",
       "   'Philosophy of physics',\n",
       "   'Philosophy of psychology',\n",
       "   'Philosophy of science',\n",
       "   'Philosophy of social science',\n",
       "   'Philosophy of space and time',\n",
       "   'Physicalism',\n",
       "   'Pierre Duhem',\n",
       "   'Positivism',\n",
       "   'Positivist',\n",
       "   'Potsdam',\n",
       "   'Pragmatism',\n",
       "   'Problem of induction',\n",
       "   'Protoscience',\n",
       "   'Province of Brandenburg',\n",
       "   'Pseudoscience',\n",
       "   'Psychologism',\n",
       "   'Psychology',\n",
       "   'Rationalism',\n",
       "   'Received view of theories',\n",
       "   'Reductionism',\n",
       "   'Relationship between religion and science',\n",
       "   'Rhetoric of science',\n",
       "   'Roger Bacon',\n",
       "   'Rudolf Carnap',\n",
       "   'Rudolf Steiner',\n",
       "   'Science studies',\n",
       "   'Scientific Revolution',\n",
       "   'Scientific essentialism',\n",
       "   'Scientific evidence',\n",
       "   'Scientific formalism',\n",
       "   'Scientific law',\n",
       "   'Scientific method',\n",
       "   'Scientific pluralism',\n",
       "   'Scientific realism',\n",
       "   'Scientific skepticism',\n",
       "   'Scientific theory',\n",
       "   'Scientism',\n",
       "   'Semantic view of theories',\n",
       "   'Sociologists',\n",
       "   'Sociology of scientific ignorance',\n",
       "   'Sociology of scientific knowledge',\n",
       "   'Structuralism (philosophy of science)',\n",
       "   'Testability',\n",
       "   'Theologians',\n",
       "   'Theory-ladenness',\n",
       "   'Theory choice',\n",
       "   'Thesis',\n",
       "   'Thomas Kuhn',\n",
       "   'Underdetermination',\n",
       "   'Uniformitarianism',\n",
       "   'Unity of science',\n",
       "   'University of Berlin',\n",
       "   'University of Göttingen',\n",
       "   'University of Jena',\n",
       "   'Vitalism',\n",
       "   'Western philosophy',\n",
       "   'Willard Van Orman Quine'],\n",
       "  'terms': ['19th-century philosophy',\n",
       "   'A priori and a posteriori',\n",
       "   'Albert Schweitzer',\n",
       "   'Alfred North Whitehead',\n",
       "   'Analytic–synthetic distinction',\n",
       "   'Anti-realism',\n",
       "   'Archive.org',\n",
       "   'Auguste Comte',\n",
       "   'Baden School',\n",
       "   'Bas van Fraassen',\n",
       "   'Bertrand Russell',\n",
       "   'C. D. Broad',\n",
       "   'Carl Gustav Hempel',\n",
       "   'Causality',\n",
       "   'Charles Sanders Peirce',\n",
       "   'Coherentism',\n",
       "   'Commensurability (philosophy of science)',\n",
       "   'Confirmation holism',\n",
       "   'Consilience',\n",
       "   'Construct (philosophy)',\n",
       "   'Constructive empiricism',\n",
       "   'Constructive realism',\n",
       "   'Constructivist epistemology',\n",
       "   'Contextualism',\n",
       "   'Conventionalism',\n",
       "   'Creative synthesis',\n",
       "   'Criticism of science',\n",
       "   'David Hume',\n",
       "   'Deductive-nomological model',\n",
       "   'Demarcation problem',\n",
       "   'Descriptive research',\n",
       "   'Determinism',\n",
       "   'Doctoral advisor',\n",
       "   'Empirical evidence',\n",
       "   'Empiricism',\n",
       "   'Epistemological anarchism',\n",
       "   'Epistemology',\n",
       "   'Ernst Troeltsch',\n",
       "   'Evidence-based practice',\n",
       "   'Evolutionism',\n",
       "   'Explanatory power',\n",
       "   'Fact',\n",
       "   'Faith and rationality',\n",
       "   'Fallibilism',\n",
       "   'Falsifiability',\n",
       "   'Feminist method',\n",
       "   'Foundationalism',\n",
       "   'Francis Bacon',\n",
       "   'Frederick C. Beiser',\n",
       "   'Functional contextualism',\n",
       "   'Galileo Galilei',\n",
       "   'Georg Wilhelm Friedrich Hegel',\n",
       "   'German Empire',\n",
       "   'Grand Duchy of Baden',\n",
       "   'Hans Reichenbach',\n",
       "   'Hard and soft science',\n",
       "   'Heidelberg',\n",
       "   'Heinrich Rickert',\n",
       "   'Heinz Heimsoeth',\n",
       "   'Henri Poincaré',\n",
       "   'Hermann Lotze',\n",
       "   'Historicism',\n",
       "   'History and philosophy of science',\n",
       "   'Hypothetico-deductive model',\n",
       "   'Ian Hacking',\n",
       "   'Idiographic',\n",
       "   'Ignoramus et ignorabimus',\n",
       "   'Immanuel Kant',\n",
       "   'Imre Lakatos',\n",
       "   'Index of philosophy of science articles',\n",
       "   'Inductionism',\n",
       "   'Inductive reasoning',\n",
       "   'Inquiry',\n",
       "   'Instrumentalism',\n",
       "   'Intertheoretic reduction',\n",
       "   'Isaac Newton',\n",
       "   'Johann Friedrich Herbart',\n",
       "   'Karl Pearson',\n",
       "   'Karl Popper',\n",
       "   'Kingdom of Prussia',\n",
       "   'Larry Laudan',\n",
       "   'List of philosophers of science',\n",
       "   'List of schools of philosophy',\n",
       "   'Max Weber',\n",
       "   'Metaphysics',\n",
       "   'Michael Polanyi',\n",
       "   'Model-dependent realism',\n",
       "   'Naturalism (philosophy)',\n",
       "   'Nature (philosophy)',\n",
       "   'Neo-Kantianism',\n",
       "   'Nomothetic',\n",
       "   'Nomothetic and idiographic',\n",
       "   'Normative science',\n",
       "   'Objectivity (philosophy)',\n",
       "   'Observation',\n",
       "   'Otto Neurath',\n",
       "   'Paradigm',\n",
       "   'Paul Feyerabend',\n",
       "   'Philosopher',\n",
       "   'Philosophical analysis',\n",
       "   'Philosophical logic',\n",
       "   'Philosophy of archaeology',\n",
       "   'Philosophy of biology',\n",
       "   'Philosophy of chemistry',\n",
       "   'Philosophy of economics',\n",
       "   'Philosophy of geography',\n",
       "   'Philosophy of history',\n",
       "   'Philosophy of linguistics',\n",
       "   'Philosophy of physics',\n",
       "   'Philosophy of psychology',\n",
       "   'Philosophy of science',\n",
       "   'Philosophy of social science',\n",
       "   'Philosophy of space and time',\n",
       "   'Physicalism',\n",
       "   'Pierre Duhem',\n",
       "   'Positivism',\n",
       "   'Positivist',\n",
       "   'Potsdam',\n",
       "   'Pragmatism',\n",
       "   'Problem of induction',\n",
       "   'Protoscience',\n",
       "   'Province of Brandenburg',\n",
       "   'Pseudoscience',\n",
       "   'Psychologism',\n",
       "   'Psychology',\n",
       "   'Rationalism',\n",
       "   'Received view of theories',\n",
       "   'Reductionism',\n",
       "   'Relationship between religion and science',\n",
       "   'Rhetoric of science',\n",
       "   'Roger Bacon',\n",
       "   'Rudolf Carnap',\n",
       "   'Rudolf Steiner',\n",
       "   'Science studies',\n",
       "   'Scientific Revolution',\n",
       "   'Scientific essentialism',\n",
       "   'Scientific evidence',\n",
       "   'Scientific formalism',\n",
       "   'Scientific law',\n",
       "   'Scientific method',\n",
       "   'Scientific pluralism',\n",
       "   'Scientific realism',\n",
       "   'Scientific skepticism',\n",
       "   'Scientific theory',\n",
       "   'Scientism',\n",
       "   'Semantic view of theories',\n",
       "   'Sociologists',\n",
       "   'Sociology of scientific ignorance',\n",
       "   'Sociology of scientific knowledge',\n",
       "   'Structuralism (philosophy of science)',\n",
       "   'Testability',\n",
       "   'Theologians',\n",
       "   'Theory-ladenness',\n",
       "   'Theory choice',\n",
       "   'Thesis',\n",
       "   'Thomas Kuhn',\n",
       "   'Underdetermination',\n",
       "   'Uniformitarianism',\n",
       "   'Unity of science',\n",
       "   'University of Berlin',\n",
       "   'University of Göttingen',\n",
       "   'University of Jena',\n",
       "   'Vitalism',\n",
       "   'Western philosophy',\n",
       "   'Willard Van Orman Quine'],\n",
       "  'Wilhelm Windelband': ['19th-century philosophy',\n",
       "   'A priori and a posteriori',\n",
       "   'Albert Schweitzer',\n",
       "   'Alfred North Whitehead',\n",
       "   'Analytic–synthetic distinction',\n",
       "   'Anti-realism',\n",
       "   'Archive.org',\n",
       "   'Auguste Comte',\n",
       "   'Baden School',\n",
       "   'Bas van Fraassen',\n",
       "   'Bertrand Russell',\n",
       "   'C. D. Broad',\n",
       "   'Carl Gustav Hempel',\n",
       "   'Causality',\n",
       "   'Charles Sanders Peirce',\n",
       "   'Coherentism',\n",
       "   'Commensurability (philosophy of science)',\n",
       "   'Confirmation holism',\n",
       "   'Consilience',\n",
       "   'Construct (philosophy)',\n",
       "   'Constructive empiricism',\n",
       "   'Constructive realism',\n",
       "   'Constructivist epistemology',\n",
       "   'Contextualism',\n",
       "   'Conventionalism',\n",
       "   'Creative synthesis',\n",
       "   'Criticism of science',\n",
       "   'David Hume',\n",
       "   'Deductive-nomological model',\n",
       "   'Demarcation problem',\n",
       "   'Descriptive research',\n",
       "   'Determinism',\n",
       "   'Doctoral advisor',\n",
       "   'Empirical evidence',\n",
       "   'Empiricism',\n",
       "   'Epistemological anarchism',\n",
       "   'Epistemology',\n",
       "   'Ernst Troeltsch',\n",
       "   'Evidence-based practice',\n",
       "   'Evolutionism',\n",
       "   'Explanatory power',\n",
       "   'Fact',\n",
       "   'Faith and rationality',\n",
       "   'Fallibilism',\n",
       "   'Falsifiability',\n",
       "   'Feminist method',\n",
       "   'Foundationalism',\n",
       "   'Francis Bacon',\n",
       "   'Frederick C. Beiser',\n",
       "   'Functional contextualism',\n",
       "   'Galileo Galilei',\n",
       "   'Georg Wilhelm Friedrich Hegel',\n",
       "   'German Empire',\n",
       "   'Grand Duchy of Baden',\n",
       "   'Hans Reichenbach',\n",
       "   'Hard and soft science',\n",
       "   'Heidelberg',\n",
       "   'Heinrich Rickert',\n",
       "   'Heinz Heimsoeth',\n",
       "   'Henri Poincaré',\n",
       "   'Hermann Lotze',\n",
       "   'Historicism',\n",
       "   'History and philosophy of science',\n",
       "   'Hypothetico-deductive model',\n",
       "   'Ian Hacking',\n",
       "   'Idiographic',\n",
       "   'Ignoramus et ignorabimus',\n",
       "   'Immanuel Kant',\n",
       "   'Imre Lakatos',\n",
       "   'Index of philosophy of science articles',\n",
       "   'Inductionism',\n",
       "   'Inductive reasoning',\n",
       "   'Inquiry',\n",
       "   'Instrumentalism',\n",
       "   'Intertheoretic reduction',\n",
       "   'Isaac Newton',\n",
       "   'Johann Friedrich Herbart',\n",
       "   'Karl Pearson',\n",
       "   'Karl Popper',\n",
       "   'Kingdom of Prussia',\n",
       "   'Larry Laudan',\n",
       "   'List of philosophers of science',\n",
       "   'List of schools of philosophy',\n",
       "   'Max Weber',\n",
       "   'Metaphysics',\n",
       "   'Michael Polanyi',\n",
       "   'Model-dependent realism',\n",
       "   'Naturalism (philosophy)',\n",
       "   'Nature (philosophy)',\n",
       "   'Neo-Kantianism',\n",
       "   'Nomothetic',\n",
       "   'Nomothetic and idiographic',\n",
       "   'Normative science',\n",
       "   'Objectivity (philosophy)',\n",
       "   'Observation',\n",
       "   'Otto Neurath',\n",
       "   'Paradigm',\n",
       "   'Paul Feyerabend',\n",
       "   'Philosopher',\n",
       "   'Philosophical analysis',\n",
       "   'Philosophical logic',\n",
       "   'Philosophy of archaeology',\n",
       "   'Philosophy of biology',\n",
       "   'Philosophy of chemistry',\n",
       "   'Philosophy of economics',\n",
       "   'Philosophy of geography',\n",
       "   'Philosophy of history',\n",
       "   'Philosophy of linguistics',\n",
       "   'Philosophy of physics',\n",
       "   'Philosophy of psychology',\n",
       "   'Philosophy of science',\n",
       "   'Philosophy of social science',\n",
       "   'Philosophy of space and time',\n",
       "   'Physicalism',\n",
       "   'Pierre Duhem',\n",
       "   'Positivism',\n",
       "   'Positivist',\n",
       "   'Potsdam',\n",
       "   'Pragmatism',\n",
       "   'Problem of induction',\n",
       "   'Protoscience',\n",
       "   'Province of Brandenburg',\n",
       "   'Pseudoscience',\n",
       "   'Psychologism',\n",
       "   'Psychology',\n",
       "   'Rationalism',\n",
       "   'Received view of theories',\n",
       "   'Reductionism',\n",
       "   'Relationship between religion and science',\n",
       "   'Rhetoric of science',\n",
       "   'Roger Bacon',\n",
       "   'Rudolf Carnap',\n",
       "   'Rudolf Steiner',\n",
       "   'Science studies',\n",
       "   'Scientific Revolution',\n",
       "   'Scientific essentialism',\n",
       "   'Scientific evidence',\n",
       "   'Scientific formalism',\n",
       "   'Scientific law',\n",
       "   'Scientific method',\n",
       "   'Scientific pluralism',\n",
       "   'Scientific realism',\n",
       "   'Scientific skepticism',\n",
       "   'Scientific theory',\n",
       "   'Scientism',\n",
       "   'Semantic view of theories',\n",
       "   'Sociologists',\n",
       "   'Sociology of scientific ignorance',\n",
       "   'Sociology of scientific knowledge',\n",
       "   'Structuralism (philosophy of science)',\n",
       "   'Testability',\n",
       "   'Theologians',\n",
       "   'Theory-ladenness',\n",
       "   'Theory choice',\n",
       "   'Thesis',\n",
       "   'Thomas Kuhn',\n",
       "   'Underdetermination',\n",
       "   'Uniformitarianism',\n",
       "   'Unity of science',\n",
       "   'University of Berlin',\n",
       "   'University of Göttingen',\n",
       "   'University of Jena',\n",
       "   'Vitalism',\n",
       "   'Western philosophy',\n",
       "   'Willard Van Orman Quine']},\n",
       " {'Wilhelm Windelband interests': 'Wilhelm Windelband',\n",
       "  'Wilhelm Windelband disciples': 'Wilhelm Windelband',\n",
       "  'terms': 'Wilhelm Windelband',\n",
       "  'Wilhelm Windelband': 'Wilhelm Windelband'})"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_direct_links_wiki_fast(subjects_with_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence_set_wiki(args):\n",
    "    index, sent_sets, subject_dict, subject_word_dict = args\n",
    "    score = 0\n",
    "    local_pair_and_values = []\n",
    "    for pair in sent_sets:\n",
    "        local_subject= pair[0]\n",
    "        entity = pair[1]\n",
    "        \n",
    "        entity_embeddings = model.encode(entity,show_progress_bar=False)\n",
    "        embeddings = subject_dict[local_subject]\n",
    "        words = subject_word_dict[local_subject]\n",
    "        \n",
    "        if embeddings.size == 0:\n",
    "            local_pair_and_values.append([pair[0], pair[1], 0.5])\n",
    "            score+=0.5\n",
    "            continue\n",
    "            \n",
    "        cosine_similarities = np.dot(embeddings, entity_embeddings)\n",
    "        max_similarity = np.max(cosine_similarities)\n",
    "        max_similarity_index = np.argmax(cosine_similarities)\n",
    "        \n",
    "        # print(f\"Entity: {entity}\\nMost Similar: {words[max_similarity_index]} \\n Score: {max_similarity}\\n\\n \")\n",
    "        \n",
    "        if max_similarity>0.6:\n",
    "            score+=1\n",
    "            local_pair_and_values.append([pair[0],pair[1],1])\n",
    "        else:\n",
    "            local_pair_and_values.append([pair[0],pair[1],0])\n",
    "            \n",
    "    fraction = score / len(sent_sets) if len(sent_sets) > 0 else 0.5\n",
    "    return index, fraction, local_pair_and_values\n",
    "\n",
    "def scoring_parallel_version_wiki(text):\n",
    "    # print(text)\n",
    "    pairs, final_sents, subject_set, subjects_with_context, output = get_sentence_based_links_wiki(text)\n",
    "    subject_dict, subject_word_dict, subject_to_KG_links = subjects_direct_links_wiki_fast(subjects_with_context)\n",
    "    \n",
    "    output[\"Subject_direct_links\"] = subject_word_dict\n",
    "    output[\"Subject_direct_links_embeddings\"] = subject_dict\n",
    "    output[\"Subject_to_KG_links\"] = subject_to_KG_links\n",
    "    \n",
    "    # print(subject_set)\n",
    "\n",
    "    if not pairs:\n",
    "        print(\"No entity pairs found here.\")\n",
    "        return 0.5, [], final_sents\n",
    "\n",
    "    fractions = [None] * len(pairs)\n",
    "    pair_and_values = [None] * len(pairs)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n",
    "        task_args = [(index, sent_sets, subject_dict, subject_word_dict) for index, sent_sets in enumerate(pairs)]\n",
    "        results = list(executor.map(process_sentence_set_wiki, task_args))\n",
    "\n",
    "    for index, fraction, local_pair_and_values in results:\n",
    "        fractions[index] = fraction\n",
    "        pair_and_values[index] = local_pair_and_values\n",
    "\n",
    "    output[\"Sentence_wise_pairs_and_values\"] = pair_and_values\n",
    "    output[\"Sentence_wise_scores\"] = fractions\n",
    "    \n",
    "    flat_pair_and_values = [item for sublist in pair_and_values for item in sublist]\n",
    "    return fractions, flat_pair_and_values, final_sents,output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Virat Kohli is an Indian Cricketer who plays for India.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wilhelm Windelband (May 11, 1848 - October 22, 1915) was a German philosopher of the Baden School.\\nWindelband is now mainly remembered for the terms \"nomothetic\" and \"idiographic\", which he introduced.\\nThese have currency in psychology and other areas, though not necessarily in line with his original meanings.\\nWindelband was a Neo-Kantian who protested other Neo-Kantians of his time and maintained that \"to understand Kant rightly means to go beyond him\".\\nAgainst his positivist contemporaries, Windelband argued that philosophy should engage in humanistic dialogue with the natural sciences rather than uncritically appropriating its methodologies.\\nHis interests in psychology and cultural sciences represented an opposition to psychologism and historicism schools by a critical philosophic system.\\nWindelband relied in his effort to reach beyond Kant on such philosophers as Georg Wilhelm Friedrich Hegel, Johann Friedrich Herbart, and Hermann Lotze.\\nClosely associated with Windelband was Heinrich Rickert.\\nWindelband\\'s disciples were not only noted philosophers, but sociologists like Max Weber and theologians like Ernst Troeltsch and Albert Schweitzer.'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:08:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19535a328c8140ae850c4e289e7aa45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:08:56 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c430df33ac02434ab1f3685e15658188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a,b,c,o = scoring_parallel_version_wiki(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3333333333333333, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_schema(data, indent=0):\n",
    "    for key, value in data.items():\n",
    "        print(' ' * indent + f'{key}:', end=' ')\n",
    "        if isinstance(value, dict):\n",
    "            print('{')\n",
    "            print_dict_schema(value, indent + 4)\n",
    "            print(' ' * indent + '}')\n",
    "        else:\n",
    "            print(type(value).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:09:07 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8042b3500ddd44889b8ecd01b03af600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:09:07 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441e7613e8c44884aed8c656173e8a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial_Text: str\n",
      "Coref_Resolved_Text: str\n",
      "Coref_Resolved_Sentences: list\n",
      "Sentence_wise_Entities: list\n",
      "Sentence_wise_subjects: list\n",
      "Sentence_Wise_pairs: list\n",
      "Subject_direct_links: {\n",
      "    Wilhelm Windelband disciples: list\n",
      "    terms: list\n",
      "    Wilhelm Windelband interests: list\n",
      "    Wilhelm Windelband: list\n",
      "}\n",
      "Subject_direct_links_embeddings: {\n",
      "    Wilhelm Windelband disciples: ndarray\n",
      "    terms: ndarray\n",
      "    Wilhelm Windelband interests: ndarray\n",
      "    Wilhelm Windelband: ndarray\n",
      "}\n",
      "Subject_to_KG_links: {\n",
      "    Wilhelm Windelband disciples: str\n",
      "    terms: str\n",
      "    Wilhelm Windelband interests: str\n",
      "    Wilhelm Windelband: str\n",
      "}\n",
      "Sentence_wise_pairs_and_values: list\n",
      "Sentence_wise_scores: list\n"
     ]
    }
   ],
   "source": [
    "_,_,_,output = (scoring_parallel_version_wiki(text))\n",
    "\n",
    "print_dict_schema(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate = []\n",
    "minor_inaccurate = []\n",
    "major_inaccurate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742d8e9144e8483fa1c1213fd3d709b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing entries:   0%|          | 0/50 [00:00<?, ?entry/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:49:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8fd81af99941539e557f4fc2fbb001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:49:59 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6282fd5e154ac3920f0f3a91058e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49763756bd1e4f5a949052cbbeef3342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:11 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be0ac91955e4298a25800613dea56a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.686611090059366\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:24 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec2948dd2e549a19540ea7e053811b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:24 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dade5c432a254bdd873fe70efa2d4b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:31 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5741b2ccaac2442ca5871e301fbff3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:31 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbe4d9567154c359b5eaa072a79e2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.6709183673469388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056f399de75141bc985bcc3a8729033e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:37 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8998b7397041b5be8d7a8c9f0651bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5f531ec5664b578276f86e51e4818c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:47 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9707424d90484677be999024f9d16c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.4961861667744021\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed2b6a5c68e4d7b9adb255f497da5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:50:56 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36c3c78df344a119903b3daccfd1fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:51:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91b135212484fbda90926a10cac5290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:51:05 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead392631f044217a6ef1409f98d4414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.4258333333333333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:51:11 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d69be81c5546fcbf27ff5091679482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:51:11 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71a8072a6e74bfbb42bbcc097b76e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:51:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0c7ed719fa4e6d8ca15ce6fc45b799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:51:47 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bb92cd938f4f189d7ecf7840938150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.26486928104575164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:51:56 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb8bc0c804d44449e12c5e2fcc9b16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:51:56 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea653fa1d0e64f38966832d00f4edccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09418381c83346eda002421248eacb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:03 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee82ee95260e4582bbec6b431b26ca01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.3888888888888889\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08fac82310e49539736f9a747d0cf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:10 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0434b509bc804e94a54b72384014e04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bc5be2ddf4483081dd97f482e71829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:19 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863dd2f4c94c404c9f50e9be6089ba1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.4398809523809523\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:25 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8921ebddb6164d0fa002c7cd0c76eccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:25 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c597bdbde18945d3abd7151618b49eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:35 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6125c3b1c07f4d9990f68317dc57462a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:35 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32f97deac7349b9a46cf9ea7713bf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.7037037037037037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:41 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02715d1b0e9c4188a8bfd15e9f3fb85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:41 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4358a57b9a294a8c80fc192b1b6e35a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:46 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6873e08de9a14803aca9d8e6c160f269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:46 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5abd4688f44594a85e1fb1f64100ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.137037037037037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7e83d8c16f44a09ae5986f4d4ff2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:52:55 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdca8cc5542429b8adf038fbb969440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:04 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d690a4616d1744b48a93ce42545a6528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:04 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad80956f8c574d419cc1d91c11983b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.5634920634920636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:09 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e517f055247a4d26978daef6cfe40129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:10 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcc6336da754c45b3d6495edd24fefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93fb2c3a5f241998aa1ed933e2758c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:15 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c7916cd478458da226536220b8e8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.5246031746031746\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:20 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28406fbd57fe4afd9b58dbff503811bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:20 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10ab2dde92b49bbbc58ad7c32a8a83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7654e913e1df4945b26829418aaa495f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:34 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc70ae8b7f2427281d6a077c4392aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.34023754023754027\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:46 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81c2e19caad45309e5294c8b8d6f881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:53:46 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603070f0f49f49a79385534567b801a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:54:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2af08af6b54942b0ca482e78f4385e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:54:08 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bf4ada899e4276bc048aeeba14020a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /opt/miniconda3/envs/myenv/lib/python3.9/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for Winnebago: As well as playing Mondo Generator gigs, two Bens, Ben Perrier (vocals, guitar) and Ben Thomas (drums) still toured as Winnebago Deal and even supported Mondo Generator , earning Winnebago Deal the moniker \"Winnebago Generator\" from fans. didn't work: \"Winnebago\" may refer to: \n",
      "Ho-Chunk\n",
      "Winnebago Tribe of Nebraska\n",
      "Winnebago language\n",
      "Winnebago (chicken)\n",
      "Winnebago Council\n",
      "Winnebago Industries\n",
      "Lake Winnebago\n",
      "Winnebago Pool\n",
      "Winnebago Scout Reservation\n",
      "Winnebago, Illinois\n",
      "Winnebago, Minnesota\n",
      "Winnebago, Nebraska\n",
      "Winnebago, Wisconsin\n",
      "Winnebago Mission, Wisconsin\n",
      "Winnebago County (disambiguation)\n",
      "Winnebago Township (disambiguation)\n",
      "Query for it: After recording tracks at Dave Grohl's Studio 606 for the next Mondo Generator album with producer Nick Raskulinecz, it was announced in July 2006 2006 that two Bens, Ben Perrier (vocals, guitar) and Ben Thomas (drums) had left Mondo Generator for \"undisclosed reasons\". didn't work: \"It\" may refer to: \n",
      "It (pronoun)\n",
      "Information technology\n",
      "It (1927 film)\n",
      "It! The Terror from Beyond Space\n",
      "It! (1967 film)\n",
      "It (1989 film)\n",
      "It (miniseries)\n",
      "It (Phish video)\n",
      "Incredible Tales\n",
      "I.T. (film)\n",
      "It (2017 film)\n",
      "It Chapter Two\n",
      "Five Children and It\n",
      "It! The Living Colossus\n",
      "A Wrinkle in Time\n",
      "It (character)\n",
      "Tatler (1901)\n",
      "International Times\n",
      "Illinois Times\n",
      "\"It!\" (short story)\n",
      "It (poetry collection)\n",
      "It (novel)\n",
      "Alexa Chung\n",
      "It (Phish festival)\n",
      "\"IT\" (XM)\n",
      "It (Pulp album)\n",
      "It (Alan Vega album)\n",
      "Tony Särkkä\n",
      "The Lamb Lies Down on Broadway\n",
      "Sign \"O\" the Times\n",
      "sic\n",
      "Niki & Gabi\n",
      "Tag (game)\n",
      "It (board game)\n",
      ".it\n",
      "Inferior temporal gyrus\n",
      "IT (file format)\n",
      "earthing system\n",
      "Integration testing\n",
      "Intrathecal administration\n",
      "Isomeric transition\n",
      "it drive\n",
      "Iran Time\n",
      "Italy\n",
      "Italian language\n",
      "Air Inter\n",
      "Kingfisher Airlines\n",
      "Intelligent Transit\n",
      "Yamaha Enduro motorcycles\n",
      "Dynasty IT\n",
      "Pāṇini\n",
      "Jordan's Furniture\n",
      "I.T\n",
      "It girl\n",
      "Cousin Itt\n",
      "Getting It: The Psychology of est\n",
      "The ground truth scores are: 0.30129551820728295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:54:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c4e3383168494eb8626b70042c2166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:54:29 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26aa6b85dc442af8929941b1b3ebef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:54:36 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9a04708aaa496290df2337f6b612bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:54:36 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602069f6686e4e6a8e1775f94436d076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.4627705627705627\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:54:48 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7dd7f695ec4861b259f0bbaad25474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:54:48 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87951cb82684be297d796a2c098ef6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:54:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78144e0912f94f7aa1b076bfcb36d536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:54:54 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d7d2c91d05418396985c8d0a3e3cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.553641456582633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071da1aafbf1458b9351ba56636389f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:03 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2faf7233323d4a7cb4dacc7710853467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for Quinn: William \"Bill\" Quinn (April 28, 1912 April 22, 1994) was an American actor, best known for William \"Bill\" Quinn role as Ralph Hourback on the CBS television series The Rifleman . didn't work: \"Quinn\" may refer to: \n",
      "Quinn (soccer)\n",
      "Quinn (given name)\n",
      "Quinn (surname)\n",
      "Quinn (musician)\n",
      "Quinn, Kentucky\n",
      "Quinn, Michigan\n",
      "Quinn, Missouri\n",
      "Quinn, South Dakota\n",
      "Quinn River\n",
      "Quinn House, San Francisco\n",
      "A. V. Quinn House\n",
      "Masten-Quinn House\n",
      "Quin House\n",
      "Quinn (album)\n",
      "Mannok\n",
      "Quinn Industrial Holdings\n",
      "University College Dublin\n",
      "Quinn the Eskimo\n",
      "Quin (disambiguation)\n",
      "Quinns (disambiguation)\n",
      "Harley Quinn (disambiguation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:08 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517b54334d024469a3fb58efd3dcda6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:08 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1ed1c6ee0f4ba2bd87f35b7988fcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.3869047619047619\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b174407ed23a4a8aa32ab172e431cd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:14 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7856ba884f454bab648073e0963201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:21 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ae4f0e22a34a25810064200a52c280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:21 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edb07d33f8c4e12b4c5e0e65a95fe71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.6916666666666667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ff69260ec540cc95c8aa30af2b7af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:30 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2a50551acc4bb69c70c5f973bde39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:39 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bd39113e2f496bb573088ab839ad37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:39 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b023d2f23194b94b8c8720733401bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.46190476190476193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:45 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f2f63bfbac4be48bbd2e76c0effd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:45 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb11086755fd406a801d10cca336bc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:50 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b17ec35bea44db58659796a1035f482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:50 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1bba8e74e04f99b91bb381c0703359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.3572751322751322\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:57 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab80a9e9252d465eb51dc37ef252abab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:55:57 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c17dc7936e040cab58b565039d732e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for he: In addition to Rod Morgenstein (born April 18, 1959) work with the progressive rock band Winger, which he joined in 1987 , Rod Morgenstein (born April 18, 1959) has also performed and recorded with Steve Morse Band, Jordan Rudess Jordan Rudess , and many other artists. didn't work: \"He\" may refer to: \n",
      "He (letter)\n",
      "He (pronoun)\n",
      "He (kana)\n",
      "Ge (Cyrillic)\n",
      "Hebrew language\n",
      "He County\n",
      "He River\n",
      "Hebei\n",
      "Hessen\n",
      "He (surname)\n",
      "Zheng He\n",
      "He-He er xian\n",
      "Immortal Woman He\n",
      "\"He\" (short story)\n",
      "Katherine Anne Porter\n",
      "He (film)\n",
      "\"He\" (song)\n",
      "Jars of Clay (album)\n",
      "John Connolly\n",
      "HE...\n",
      "Hé (Chinese pastry)\n",
      "His Eminence\n",
      "Excellency\n",
      "Hektoen enteric agar\n",
      "Helium\n",
      "Hemagglutinin esterase\n",
      "Hematoxylin and eosin stain\n",
      "Hepatic encephalopathy\n",
      "High explosive\n",
      "Holocene calendar\n",
      "Holocene\n",
      "Homomorphic encryption\n",
      "High-explosive anti-tank\n",
      "High-explosive incendiary\n",
      "High-explosive incendiary/armor-piercing ammunition\n",
      "Heathrow Express\n",
      "Heinkel\n",
      "Higher education\n",
      "Hurricane Electric\n",
      "Lobotomy Corporation\n",
      "Hezhou (disambiguation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:03 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4eed3e098c749718a5e1ca0c69c7e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:04 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079631b3847643fbbcf2e00c8589ebfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.6757575757575757\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e41d486aa19421787ac8c2b0d8b157b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:10 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3648df832848f58abe955bba0e42df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:16 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7b94855d1d481dba813a9f55196068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:16 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520d09bf7ab24bb180d20c77a42391b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.33312324929971987\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d68669655b4d42b17c62f7d6e42e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:27 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2ad83a4818489492f9713cf45aa68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:38 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db4641686794bc8b5961d8c2ff6f448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:38 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a1e9af10544aef852b593c8ff8aaf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.23148148148148145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:45 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727151bbe50f43a1b1db6fc54c6837f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:45 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0363c03fe1094be0b506878b6bc56cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:51 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e5340418404719b9a120c45cbb756e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:51 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48eb41b911bb4122b7642237dfd132f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.4290674603174603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24d9bbc884a4e3a8fbc2c0036d79af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:56:58 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfad8180722246fe970b31f18d3e3b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:10 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a470fac81e74b37bdc1f3c73671dc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:10 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d55adbe9dc41738a7360f72978685e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for Castellano: Heather \"Torry\" Castellano (born January 8, 1979, in San Francisco, California) is the cousin of actress Laura San Giacomo. didn't work: \"Castellano\" may refer to: \n",
      "Castilian (disambiguation)\n",
      "Castile (historical region)\n",
      "Spanish language\n",
      "Castilian Spanish\n",
      "Castellano (surname)\n",
      "Castellano (grape)\n",
      "Castellano, Trentino\n",
      "Castellano (river)\n",
      "All pages with titles beginning with Castellano\n",
      "All pages with titles containing Castellano\n",
      "Castellanos (disambiguation)\n",
      "Castellani (disambiguation)\n",
      "Carea Castellano Manchego\n",
      "The ground truth scores are: 0.38571428571428573\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be6e6ab230e4f3a85552bafc25a2b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:19 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec67f9c8f61143e2a0445129c81ab6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a9c3c67189463eb6ae255153b9e67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:29 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa59283b2a4e4b7385947e989f9c94ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for conflict: Nevertheless, the conflict with his younger brother Dietrich continued as Albert I, the proud (de \"Albrecht I der Stolze\") (1158 24 June 1195) tried to regain the title . didn't work: \"Conflict\" may refer to: \n",
      "Conflict (process)\n",
      "Conflict continuum\n",
      "Conflict of interest\n",
      "Cultural conflict\n",
      "Ethnic conflict\n",
      "Group conflict\n",
      "Intragroup conflict\n",
      "Organizational conflict\n",
      "Role conflict\n",
      "Social conflict\n",
      "Work–family conflict\n",
      "Violence\n",
      "war\n",
      "Conflict (narrative)\n",
      "Conflict (air traffic control)\n",
      "Conflict (revision control)\n",
      "HMS Conflict\n",
      "HMS Conflict (1873)\n",
      "HMS Conflict (1894)\n",
      "Conflict (1921 film)\n",
      "Conflict (1936 film)\n",
      "Conflict (1937 film)\n",
      "Conflict (1938 film)\n",
      "Conflict (1945 film)\n",
      "Catholics: A Fable (1973 film)\n",
      "Judith (1966 film)\n",
      "Samar (1999 film)\n",
      "Conflict (series)\n",
      "Conflict (video game)\n",
      "Conflict: Middle East Political Simulator\n",
      "Conflict (novel)\n",
      "Gerard Cosloy\n",
      "Margie Harris\n",
      "board wargames\n",
      "Conflict (band)\n",
      "Conflict (Sy Smith album)\n",
      "Conflict (Jimmy Woods album)\n",
      "The Sickness\n",
      "Conflict (1978 TV series)\n",
      "Conflict (American TV series)\n",
      "\"Conflict\" (UFO)\n",
      "All pages with titles beginning with Conflict \n",
      "All pages with titles containing Conflict\n",
      "All pages with titles beginning with The Conflict\n",
      "All pages with titles containing The Conflict\n",
      "Clash (disambiguation)\n",
      "Conflict resolution\n",
      "Confrontation (disambiguation)\n",
      "Struggle (disambiguation)\n",
      "The ground truth scores are: 0.516991341991342\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bc87c376d544719b23afa8b2de87e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:37 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bea90a0b4f341429dd97cb10b42510b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for she: In addition to Sirið Stenberg work with the Faroese band Týr, in which she is the lead vocalist and plays the violin , Sirið Stenberg has released two solo albums, and has collaborated with various other Faroese and international artists. didn't work: \"She\" may refer to: \n",
      "She (pronoun)\n",
      "She County, Anhui\n",
      "She Prefecture\n",
      "She County, Hebei\n",
      "She River\n",
      "She people\n",
      "She Chinese\n",
      "She language\n",
      "She (surname)\n",
      "She (Qi)\n",
      "Empress She\n",
      "She: A History of Adventure\n",
      "She (1911 film)\n",
      "She (1916 film)\n",
      "She (1917 film)\n",
      "She (1925 film)\n",
      "She (1935 film)\n",
      "She (1965 film)\n",
      "She (1984 film)\n",
      "Ophélie Winter\n",
      "She (1954 film)\n",
      "She (1967 film)\n",
      "She (magazine)\n",
      "She (Netflix series)\n",
      "S.H.E\n",
      "Solid HarmoniE\n",
      "She (American band)\n",
      "she (Swedish band)\n",
      "she (Dalbello album)\n",
      "She (Harry Connick Jr. album)\n",
      "She (Jerusalem album)\n",
      "She (Stiltskin album)\n",
      "She (Viktor Lazlo album)\n",
      "She (Wendy Matthews album)\n",
      "s/he (album)\n",
      "She (EP)\n",
      "Monni\n",
      "Sheryn Regis\n",
      "\"She\" (Charles Aznavour song)\n",
      "\"She\" (Green Day song)\n",
      "\"She\" (Groove Coverage song)\n",
      "\"She\" (Kiss song)\n",
      "\"She\" (Tommy James and the Shondells song)\n",
      "\"She\" (Tyler, the Creator song)\n",
      "\"She\" (Zayn song)\n",
      "\"She\" (Selena Gomez song)\n",
      "Human\n",
      "Shooting Rubberbands at the Stars\n",
      "Fat Mattress II\n",
      "The Promise\n",
      "GP\n",
      "She\n",
      "Fine Line\n",
      "Mars Needs Guitars!\n",
      "Long Wave\n",
      "She\n",
      "Point of No Return\n",
      "Static Age\n",
      "More of the Monkees\n",
      "Photographs\n",
      "In Reverie\n",
      "She\n",
      "Coming Up\n",
      "Static & Silence\n",
      "Tenpenny Joke\n",
      "More of the Monkees\n",
      "She\n",
      "\"She\" (Angel)\n",
      "She (TV channel)\n",
      "episode of The Good Doctor\n",
      "Spin Hall effect\n",
      "Standard hydrogen electrode\n",
      "hydrological transport model\n",
      "Seaholme railway station\n",
      "ARC Centre of Excellence for the History of Emotions\n",
      "Shenyang Taoxian International Airport\n",
      "environment, health and safety\n",
      "Sherborne railway station\n",
      "Siu Hei stop\n",
      "All pages with titles beginning with She \n",
      "All pages with titles beginning with She-\n",
      "All pages with titles containing She\n",
      "All pages with titles containing She-\n",
      "Shi (disambiguation)\n",
      "He and She (disambiguation)\n",
      "Shae (disambiguation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:42 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddb1ace99364133955b5b466263b5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:42 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8b1310748f41d28de3297643f7f469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.4365079365079365\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2c5d5541474c6483f268093aed960e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:47 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4038c867ba64e7997af391f43712076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:52 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd4b1780b7644e78b764dae53818aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:52 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d57e999a6d4e21a14a1471f9e661b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.64421768707483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12ebdac92884bd38480682cc1b0351e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:57:58 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1b7376c34041daa9e68217dcb84b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:58:11 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1e0aed09e3458489465ab1c48ee99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:58:11 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a07a367c4bd40409a905c12ee55d701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.6599999999999999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:58:17 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa524ed7790409eb0be0482dd4e3201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:58:17 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85eccf926854f12a20ce0f5f324a148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:58:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77621ac4d0c84416a027ec83c00fbb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:58:27 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5122f14f10944e86826c4a03107efbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.4964113181504486\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:58:46 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530923c038424de9b2adfa60dd659581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:58:46 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d6dbca243d44b4bf1b6f93414f5579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:58:53 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3635cd914e94127aaef8a78c8fbf9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:58:53 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51603be2687d460490c1007af8b56daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.33141025641025645\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:59:01 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3117a1637a994476ae9dfb6dca056e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:59:01 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e283554cd8074055a518829491562564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:59:07 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c75f5f199e446386f5952575329c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:59:07 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e242e7c25f14893921f9a6fef18307c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.5409226190476191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:59:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15da15fc6b184d3c8155cbf4889e221d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:59:14 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0656d108e7c94b728393d472d809c327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:59:49 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8c7f86790649bdbacfad37d213182a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:59:49 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190d52c7a38b4f1195b4106c2cbb64bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.4203703703703704\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:59:55 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517cc7dae73c43c4bac8fa36ade5acf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 16:59:55 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac97cdc8bf7491a8e45c787267dd557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:00 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e2c7cd0bfa4ab09084f622c79339b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:00 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b51a655031482c89c030b35b7908b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.356060606060606\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:06 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f783822b1f4489b8cc2d918efe8ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:06 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8470bc1c9f4340b58c8614eb39b3452b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9248349a99b043078f299caeed01f138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:14 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9206a1d7fb86410494f66c038460c332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:21 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3191763addec473a9b1cf06e15ede7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:21 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1b190ca99b424f89d2f2277d48a9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for Zhuang: \"Zhuang of Chu Chu (died 621 BC ) was the last ruler of the state of Chu during the Spring and Autumn period of ancient China. didn't work: \"Zhuang\" may refer to: \n",
      "Zhuang people\n",
      "Zhuang languages\n",
      "Zhuang logogram\n",
      "Zhuang Zhou\n",
      "Zhuang (surname)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:27 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7070d6e6b67473fb91758424e4098e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:27 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daba870e1f5e4b09bdc98641a3db16e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for which: In 611 BC King Zhuang of Chu (died 591 BC) annexed the state of Yong (庸国), a move which made Chu much stronger. didn't work: \"Which\" may refer to: \n",
      "relative pronoun\n",
      "English interrogative word\n",
      "which (command)\n",
      "Which?\n",
      "English relative clauses\n",
      "Interrogative clause\n",
      "Whicher (disambiguation)\n",
      "All pages with titles containing Which\n",
      "Query for output: Chu agricultural output improved significantly during his reign , aided by Sunshu Ao comprehensive dam-works and an enormous planned reservoir created in modern-day northern Anhui province. didn't work: \"Output\" may refer to: \n",
      "Input/output\n",
      "state (computer science)\n",
      "Output (economics)\n",
      "Gross output\n",
      "Net output\n",
      "Power (physics)\n",
      "Dependent variable\n",
      "Output (album)\n",
      "Input (disambiguation)\n",
      "Query for minister: When a particularly senior minister challenged King Zhuang of Chu (died 591 BC) through a riddle, King Zhuang of Chu (died 591 BC) responded that King Zhuang of Chu (died 591 BC) had been waiting for three years for someone from King Zhuang of Chu (died 591 BC) court to show some didn't work: \"Minister\" may refer to: \n",
      "Minister (Christianity)\n",
      "Minister (Catholic Church)\n",
      "Minister (government)\n",
      "Minister without portfolio\n",
      "Shadow Cabinet\n",
      "Minister (Austria)\n",
      "Minister (diplomacy)\n",
      "Ministerialis\n",
      "The Minister\n",
      "Ministry (disambiguation)\n",
      "Minster (disambiguation)\n",
      "Yes Minister\n",
      "The ground truth scores are: 0.26126984126984126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:34 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc072d286bc342c9a3d48d498f4416de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:35 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779079eefd4e4c2889834d29319a473e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:47 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81380784e9bd45719209c4f7c7bff441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:00:47 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405275b9267f4073ba90bbd43a942814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for Flanagan household: The Flanagan household consisted of eight children Patricia Mary, Admiral William J. Flanagan, Jr., born on March 27, 1943, , Kathleen, John J., Peter A., Mary Margaret, Anne, and Joseph M. William J. Flanagan, Sr. was a member of the Massachusetts National Guard. didn't work: \"Mark Flanagan\" may refer to: \n",
      "Mark Flanagan (actor)\n",
      "Mark Flanagan (boxer)\n",
      "Mark Flanagan (chef)\n",
      "Mark Flanagan (communications)\n",
      "Mark Flanagan (musician)\n",
      "Mark Flanagan (rugby league)\n",
      "Mark Flanagan (rugby union)\n",
      "Largo\n",
      "Mark G. Flanagan\n",
      "Marc Flanagan\n",
      "The ground truth scores are: 0.31020408163265306\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2320c555720457f93dd78e0a7a0c9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:05 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8fc09824474814b428b8e59061fbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea8dd8960714ea68ff39d2740681e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:12 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3116b822bf84ceb88338ffdaa876155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for identity: Despite the existence of Hendrik van Rheede's over the last three centuries, the correct taxonomic identity of many plants listed in Hortus Malabaricus , many plants listed in Hortus Malabaricus medicinal properties, methods of use, etc., as described and codified by renowned tra didn't work: \"Identity\" may refer to: \n",
      "Identity document\n",
      "Identity (philosophy)\n",
      "Identity (social science)\n",
      "Identity (mathematics)\n",
      "Identity (1987 film)\n",
      "Identity (2003 film)\n",
      "Identity (game show)\n",
      "Identity (TV series)\n",
      "\"Identity\" (Arrow)\n",
      "\"Identity\" (Burn Notice)\n",
      "\"Identity\" (Charlie Jade)\n",
      "\"Identity\" (Legend of the Seeker)\n",
      "\"Identity\" (Law & Order: Special Victims Unit episode)\n",
      "\"Identity\" (NCIS: Los Angeles)\n",
      "Identity (3T album)\n",
      "Identity (BoA album)\n",
      "Identity (Far East Movement album)\n",
      "Identity (Robert Pierre album)\n",
      "Identity (Raghav album)\n",
      "Identity (Victon EP)\n",
      "Identity (Zee album)\n",
      "\"Identity\" (Sakanaction song)\n",
      "\"Identity\" (X-Ray Spex song)\n",
      "London Town\n",
      "The Art of Survival\n",
      "Identity (music)\n",
      "Identity (tuning)\n",
      "Aboriginal Publications Foundation\n",
      "Identity (novel)\n",
      "Accounting identity\n",
      "Brand identity\n",
      "Corporate identity\n",
      "Identity (philosophy)\n",
      "Law of identity\n",
      "Personal identity\n",
      "Identity (social science)\n",
      "Political identity\n",
      "Digital identity\n",
      "Identity (object-oriented programming)\n",
      "Identity (mathematics)\n",
      "Identity element\n",
      "Identity function\n",
      "Identity matrix\n",
      "Identity document\n",
      "All pages with titles beginning with Identity\n",
      "All pages with titles containing Identity\n",
      "Biometrics\n",
      "Collective identity\n",
      "Cultural diversity\n",
      "Cultural identity\n",
      "Entity (disambiguation)\n",
      "ID (disambiguation)\n",
      "Identification (disambiguation)\n",
      "Identifier\n",
      "Identity politics\n",
      "National identity\n",
      "Outline of self\n",
      "Personal data\n",
      "Personal identity (disambiguation)\n",
      "Secret identity (disambiguation)\n",
      "The Bourne Identity (disambiguation)\n",
      "The ground truth scores are: 0.45626721763085404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:22 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368df1ddb8a647e89dcbf7ead3e8440e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:22 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f38b75e66348aeb0c9f5cc42fd0bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49f77d0647b436a9bae22e81ec3cec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:33 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3cb88abac6441db64d6990cf9d7353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.15782312925170067\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:40 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b0d6cbc5d24749b29c416621039757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:40 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b473fb514d4341a18e445bb194baa504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:45 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8594b7634a4448c8b220e7d68d0507ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:46 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60886804fd624ce299422ac858f0a88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.3222222222222222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:51 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0c8aaf8e254e07b9a026ee624652db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:51 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc06f2681d644b4a9761551b6fa87f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for work: Hilda Kuper most famous work, An African Aristocracy Rank Among the Swazi (1944), is considered a classic in the field of anthropology. didn't work: \"Work\" may refer to: \n",
      "5 See also\n",
      "Work (human activity)\n",
      "Manual labour\n",
      "House work\n",
      "Working animal\n",
      "Work (physics)\n",
      "Work (electric field)\n",
      "Work (thermodynamics)\n",
      "Creative work\n",
      "Work of art\n",
      "WORK (FM)\n",
      "WORK-LP\n",
      "WOYK\n",
      "The Work (band)\n",
      "Work Group\n",
      "Work (EP)\n",
      "Work!\n",
      "Work 1989–2002\n",
      "Work (album)\n",
      "\"Work\" (ASAP Ferg song)\n",
      "\"Work\" (Iggy Azalea song)\n",
      "\"Work\" (Ciara song)\n",
      "\"Work\" (Jars of Clay song)\n",
      "\"Work\" (Jimmy Eat World song)\n",
      "\"Work\" (Rihanna song)\n",
      "\"Work\" (Kelly Rowland song)\n",
      "\"Work\" (The Saturdays song)\n",
      "\"Work\" (The 2 Bears song)\n",
      "Uprising\n",
      "Grand Hustle Presents: In da Streetz Volume 4\n",
      "Moment of Truth\n",
      "Everyone Afraid to Be Forgotten\n",
      "Jme\n",
      "Wanderlust\n",
      "Songs for Drella\n",
      "Thelonious Monk\n",
      "Charlotte Day Wilson\n",
      "Golden Hour: Part 1\n",
      "Work (film)\n",
      "Work (painting)\n",
      "Work (professional wrestling)\n",
      "Work (vehicle)\n",
      "\"Work\" (The Armando Iannucci Shows)\n",
      "Work: A Story of Experience\n",
      "Good works\n",
      "Slack Technologies\n",
      "Ron Milner\n",
      "Delta Work\n",
      "Jimmy Work\n",
      "John Work (fur trader)\n",
      "John M. Work\n",
      "John Wesley Work Jr.\n",
      "John Wesley Work III\n",
      "John Work House and Mill Site\n",
      "John Work Garrett\n",
      "John Work Scott\n",
      "Milton Work\n",
      "Career\n",
      "Critique of work\n",
      "Employment\n",
      "Karma\n",
      "Labour (disambiguation)\n",
      "Refusal of work\n",
      "Wage labour\n",
      "Wage slavery\n",
      "Work ethic\n",
      "Work of art (disambiguation)\n",
      "Work Work (disambiguation)\n",
      "Working (disambiguation)\n",
      "Works (disambiguation)\n",
      "The Works (disambiguation)\n",
      "All pages with titles containing Work\n",
      "All pages with titles beginning with Work \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:58 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c45903abc6404c8e1b3d8f4ad5c0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:01:58 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e81454a6c24f00a331b2b896951926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.37050264550264544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a4278367ca491180e3860516c91594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:05 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1c677e8fa849019376b377e73e0a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:12 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb31426d87b84681a437c5088039addc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:12 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d9aee569154307abff232584f9409a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.5777777777777778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:23 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bc6b03a8914e90aec93cc121ed17be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:23 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82651188d358400cb06da0f34edd2521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:33 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4c4ab78d31480885505d1e903a47c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:33 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c940f79cea5d410bbfc84e837c0217b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.40740740740740744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:39 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef9605668b3457e87ec14675c5f0c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:39 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cc8369541641459e73e7d936ebad7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:44 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6718ce727a6c43ed8f4fc84109ef53a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:45 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82e47f642d547a6a5c5928fc4572888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.375\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:50 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7aac8b03e824df1a1212d70e67c5255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:50 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fc79fabdb043d08884290c70e5d707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:59 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a113141cdb2b4ce6a1b1d6d1e857d731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:02:59 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e701458f5b4248961f907c4e13bd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.5006410256410256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:03:05 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4216f5fae394db3bce0a92fbfe5583d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:03:05 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ef84539fe74fd9ac90f624691e6d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:03:16 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc18cf419d046589b6e2f49e7eb4b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:03:16 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cd8d9429d2431690382442295e1040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.36271929824561405\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:03:30 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756339607da142409e9132dbf20770de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:03:30 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1218a858283548abaa7b5034ac75c2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:03:39 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5568fe81fb54d9e993a7634d452a1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:03:39 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5883de5dbc345e49cbe995230ab739e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.32863969363969364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:03:54 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf8c58162a7429fba2168a9b05cd950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:03:54 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbb3fd94d8c46bca9848d1337f7eb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:04 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c369c6679e404c448aa597b0c5270b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:04 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4a684c89f04de4be0177258d7b17cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.5333333333333333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:14 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07657236f3fa46f7b84f106fdb7e634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:14 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc45beb26f74ea79a2ebda7a4d434c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:19 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d22ecb9f724f958ea2603b28e0dd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:19 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3974196a4db94b7b9af919fa4da05757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.6534722222222222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:29 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c175e84704a848b1bbfa9f0b820b0d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:29 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68867704a2e84349902ffc55be72e530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:37 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c911194c2edd4ae0b95a2d94f1e4d2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:37 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a7dbf0555f4131b2b0d0448d573a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.3034920634920635\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:45 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6720169c18741dda30634d45dbf7c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:45 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631aa015262e47a19b1768ec2d06d089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:52 - INFO - \t Tokenize 1 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dac8cbdf124a24860468710567cac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/04/2024 17:04:52 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c0637ef9d04184ac96f3787157e36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ground truth scores are: 0.2702947845804989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"Output\"\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "for i in tqdm(range(0,50), desc=\"Processing entries\", unit=\"entry\"):\n",
    "    list_of_sentences = (dataset[\"evaluation\"][i][\"gpt3_sentences\"])\n",
    "    sentences = ''''''\n",
    "    for s in list_of_sentences:\n",
    "        tmp = preprocess_text(s)\n",
    "        if tmp[-1]!='.':\n",
    "            tmp+='.'\n",
    "        sentences = sentences + tmp + \"\\n\" \n",
    "        \n",
    "    # sentences = sentences.strip()\n",
    "    # raw = dataset[\"evaluation\"][i][\"wiki_bio_text\"]\n",
    "    \n",
    "    ground_truth_doc = preprocessing(dataset[\"evaluation\"][i][\"wiki_bio_text\"])\n",
    "    ground_truth = ''''''\n",
    "    for sent in ground_truth_doc.sents:\n",
    "        temp = preprocess_text(sent.text.strip())  \n",
    "        if temp:\n",
    "            if temp[-1] not in '.!?': \n",
    "                temp += '.'\n",
    "            ground_truth += temp + \"\\n\"\n",
    "\n",
    "    ground_truth = ground_truth.strip()\n",
    "    # print(ground_truth)\n",
    "    \n",
    "    annotation = dataset[\"evaluation\"][i][\"annotation\"]\n",
    "    \n",
    "    sentences_scores, sentence_pairs_and_values , sentence_coref_sents, output1= scoring_parallel_version_wiki(sentences)\n",
    "    ground_truth_scores, ground_pairs_and_values, ground_coref_sents, output2 = scoring_parallel_version_wiki(ground_truth)\n",
    "    output1[\"Sentence_Wise_Annotations\"] = annotation\n",
    "    output2[\"Sentence_Wise_Annotations\"] = [\"accurate\"]*len(output2[\"Coref_Resolved_Sentences\"])\n",
    "    \n",
    "    outputs.append(output2)\n",
    "    if len(sentences_scores)==len(annotation):\n",
    "        outputs.append(output1)\n",
    "    \n",
    "        \n",
    "    filename = os.path.join(folder_name, f\"entry_{i+1}.txt\")\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"#############SENTENCE_PAIRS############\\n\\n\")\n",
    "        for x in range(len(sentence_pairs_and_values)):\n",
    "            file.write(f\"{sentence_pairs_and_values[x][0]} and {sentence_pairs_and_values[x][1]} and the value is : {sentence_pairs_and_values[x][2]}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"#############GROUND_PAIRS############\\n\\n\")\n",
    "        for x in range(len(ground_pairs_and_values)):\n",
    "            file.write(f\"{ground_pairs_and_values[x][0]} and {ground_pairs_and_values[x][1]} and the value is : {ground_pairs_and_values[x][2]}\\n\")\n",
    "        file.write(\"\\n\\n\")\n",
    "        file.write(\"%%%%%%%%%%%%%%%%%%%%SENTENCES%%%%%%%%%%%%%%%%%\\n\")\n",
    "        file.write(f\"Sentences : \\n\\n{sentences}\\n\\n\")\n",
    "        file.write(f\"Coref Resolved: \\n\\n\")\n",
    "        for y,x in enumerate(sentence_coref_sents):\n",
    "            file.write(f\"{y}. {x}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"%%%%%%%%%%%%%%%%%%%%GROUND_TRUTH%%%%%%%%%%%%%%%\\n\")\n",
    "        file.write(f\"Ground Truth : \\n\\n{ground_truth} \\n\\n\")\n",
    "        file.write(f\"Coref Resolved: \\n\\n\")\n",
    "        for y,x in enumerate(ground_coref_sents):\n",
    "            file.write(f\"{y}. {x}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"%%%%%%%%%%%%%%%%%%%%FRACTIONS%%%%%%%%%%%%%%%%%%\\n\")\n",
    "        file.write(f\"Value for sentences is : \\n\")\n",
    "        for x in sentences_scores:\n",
    "            file.write(f\"{x} \")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(f\"Value for ground truth is : \\n\")\n",
    "        for x in ground_truth_scores:\n",
    "            file.write(f\"{x} \")\n",
    "        file.write(\"\\n\\n\")\n",
    "        file.write(\"%%%%%%%%%%%%%%%%%%%%ANNOTATIONS%%%%%%%%%%%%%%%%\\n\")\n",
    "        for x in annotation:\n",
    "            file.write(f\"{x} \")\n",
    "        file.write(\"\\n\\n\")\n",
    "        \n",
    "    \n",
    "    if len(ground_truth_scores)>0:\n",
    "        print(f\"The ground truth scores are: {sum(ground_truth_scores)/len(ground_truth_scores)}\\n\")\n",
    "\n",
    "    for scores in ground_truth_scores:\n",
    "            accurate.append(scores)\n",
    "            \n",
    "    if len(sentences_scores)!=len(annotation):\n",
    "        continue\n",
    "    \n",
    "    for t,score in enumerate(sentences_scores):\n",
    "        if annotation[t-1]==\"accurate\":\n",
    "            accurate.append(score) \n",
    "        elif annotation[t-1]==\"minor_inaccurate\":\n",
    "            minor_inaccurate.append(score)\n",
    "        elif annotation[t-1]==\"major_inaccurate\":\n",
    "            major_inaccurate.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4302239242785771\n"
     ]
    }
   ],
   "source": [
    "avrg_accurate = sum(accurate)/len(accurate)\n",
    "print(avrg_accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4238847837985769\n"
     ]
    }
   ],
   "source": [
    "avrg_minor = sum(minor_inaccurate)/len(minor_inaccurate)\n",
    "print(avrg_minor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(minor_inaccurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42376283846872087\n"
     ]
    }
   ],
   "source": [
    "avrg_major = sum(major_inaccurate)/len(major_inaccurate)\n",
    "print(avrg_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(major_inaccurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.423815424558919\n"
     ]
    }
   ],
   "source": [
    "avrg_inaccurate = (sum(minor_inaccurate) + sum(major_inaccurate))/(len(minor_inaccurate) + len(major_inaccurate))\n",
    "print(avrg_inaccurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_accurate = ((avrg_accurate)+(avrg_inaccurate))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for score in accurate + minor_inaccurate + major_inaccurate:\n",
    "    if score >= threshold_accurate:\n",
    "        predicted_labels.append(\"accurate\")\n",
    "    else:\n",
    "        predicted_labels.append(\"inaccurate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [\"accurate\"] * len(accurate) + [\"inaccurate\"] * len(minor_inaccurate) + [\"inaccurate\"] * len(major_inaccurate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accurate': {'Precision': 0.712890625, 'Recall': 0.5391432791728212, 'F1 Score': 0.6139613120269133}, 'inaccurate': {'Precision': 0.28110599078341014, 'Recall': 0.45353159851301117, 'F1 Score': 0.3470839260312945}}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize counters\n",
    "confusion_matrix = defaultdict(lambda: {\"TP\": 0, \"FP\": 0, \"FN\": 0, \"TN\": 0})\n",
    "\n",
    "# Calculate confusion matrix\n",
    "for true, pred in zip(true_labels, predicted_labels):\n",
    "    for category in [\"accurate\", \"inaccurate\"]:\n",
    "        if true == category and pred == category:\n",
    "            confusion_matrix[category][\"TP\"] += 1\n",
    "        elif true == category and pred != category:\n",
    "            confusion_matrix[category][\"FN\"] += 1\n",
    "        elif true != category and pred == category:\n",
    "            confusion_matrix[category][\"FP\"] += 1\n",
    "        elif true != category and pred != category:\n",
    "            confusion_matrix[category][\"TN\"] += 1\n",
    "\n",
    "metrics = {}\n",
    "for category in confusion_matrix:\n",
    "    TP = confusion_matrix[category][\"TP\"]\n",
    "    FP = confusion_matrix[category][\"FP\"]\n",
    "    FN = confusion_matrix[category][\"FN\"]\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    metrics[category] = {\"Precision\": precision, \"Recall\": recall}\n",
    "    \n",
    "for category in metrics:\n",
    "    precision = metrics[category][\"Precision\"]\n",
    "    recall = metrics[category][\"Recall\"]\n",
    "\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    metrics[category][\"F1 Score\"] = f1_score\n",
    "\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = []\n",
    "prediction = []\n",
    "temp_actual = []\n",
    "scores = []\n",
    "subject = []\n",
    "subject_to_kg = []\n",
    "direct_links_from_subject = []\n",
    "direct_link_embeddings = []\n",
    "sentence_pairs_and_values = []\n",
    "base_text = []\n",
    "base_text_coref_resolved = []\n",
    "sentence_wise_entities = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in outputs:\n",
    "    sentence += output[\"Coref_Resolved_Sentences\"]\n",
    "    scores += output[\"Sentence_wise_scores\"]\n",
    "    \n",
    "    for score in output[\"Sentence_wise_scores\"]:\n",
    "        if score >= threshold_accurate:\n",
    "            prediction.append(\"accurate\")\n",
    "        else:\n",
    "            prediction.append(\"inaccurate\")\n",
    "            \n",
    "    temp_actual += output[\"Sentence_Wise_Annotations\"]\n",
    "    subject += output[\"Sentence_wise_subjects\"]\n",
    "    sentence_wise_entities += output[\"Sentence_wise_Entities\"]\n",
    "    \n",
    "    subject_link_map = output[\"Subject_direct_links\"]\n",
    "    subject_link_embedding_map = output[\"Subject_direct_links_embeddings\"]\n",
    "    subject_kg_map = output[\"Subject_to_KG_links\"]\n",
    "    \n",
    "    direct_links_from_subject += [subject_link_map[subj] if subj is not None else [] for subj in output[\"Sentence_wise_subjects\"]]\n",
    "    direct_link_embeddings += [subject_link_embedding_map[subj] if subj is not None else [] for subj in output[\"Sentence_wise_subjects\"]]\n",
    "    subject_to_kg += [subject_kg_map[subj] if subj is not None else \"\" for subj in output[\"Sentence_wise_subjects\"]]\n",
    "    \n",
    "    sentence_pairs_and_values += output[\"Sentence_wise_pairs_and_values\"]\n",
    "    base_text += ([output[\"Initial_Text\"]]*len(output[\"Coref_Resolved_Sentences\"]))\n",
    "    base_text_coref_resolved += ([output[\"Coref_Resolved_Text\"]]*len(output[\"Coref_Resolved_Sentences\"]))\n",
    "    \n",
    "actual = [\"inaccurate\" if item in [\"minor_inaccurate\", \"major_inaccurate\"] else item for item in temp_actual]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Sentence: 946\n",
      "Length of Prediction: 946\n",
      "Length of Actual: 946\n",
      "Length of Scores: 946\n",
      "Length of Subject: 946\n",
      "Length of Direct Links from Subject: 946\n",
      "Length of Direct Link Embeddings: 946\n",
      "Length of Subject to Knowledge Graph Linking : 946\n",
      "Length of Sentence Pairs and Values: 946\n",
      "Length of Base Text: 946\n",
      "Length of Base Text Coref Resolved: 946\n",
      "Length of Sentence Wise Entities: 946\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of Sentence:\", len(sentence)) \n",
    "print(\"Length of Prediction:\", len(prediction))\n",
    "print(\"Length of Actual:\", len(actual))\n",
    "print(\"Length of Scores:\", len(scores))\n",
    "print(\"Length of Subject:\", len(subject))\n",
    "print(\"Length of Direct Links from Subject:\", len(direct_links_from_subject))\n",
    "print(\"Length of Direct Link Embeddings:\", len(direct_link_embeddings))\n",
    "print(\"Length of Subject to Knowledge Graph Linking :\", len(subject_to_kg))\n",
    "print(\"Length of Sentence Pairs and Values:\", len(sentence_pairs_and_values))\n",
    "print(\"Length of Base Text:\", len(base_text))\n",
    "print(\"Length of Base Text Coref Resolved:\", len(base_text_coref_resolved))\n",
    "print(\"Length of Sentence Wise Entities:\", len(sentence_wise_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= {\n",
    "    \"sentence\": sentence,\n",
    "    \"prediction\": prediction,\n",
    "    \"actual\": actual,\n",
    "    \"entities\": sentence_wise_entities,\n",
    "    \"pairs\": sentence_pairs_and_values,\n",
    "    \"subject\": subject,\n",
    "    \"subject-KB Link\": subject_to_kg,\n",
    "    \"direct_links_from_subject\": direct_links_from_subject,\n",
    "    \"scores\": scores,\n",
    "    \"direct_link_embeddings\": direct_link_embeddings,\n",
    "    \"base_text\": base_text,\n",
    "    \"base_text_coref_resolved\": base_text_coref_resolved\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully exported to Excel: 'output_data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "excel_file = 'output_data.xlsx'\n",
    "df.to_excel(excel_file, index=False, sheet_name='Sheet1')\n",
    "print(f\"DataFrame successfully exported to Excel: '{excel_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['Addiction medicine', 'Addiction psychiatry', 'Adolescent medicine', 'Allergy', 'Allied health professions', 'Alternative medicine', 'Anatomical pathology', 'Andrology', 'Anesthesiology', 'Angiology', 'Aviation medicine', 'Bachelor of Medical Sciences', 'Bachelor of Medicine, Bachelor of Surgery', 'Bertrand Dawson, 1st Viscount Dawson of Penn', 'Cardiac surgery', 'Cardiology', 'Cardiothoracic surgery', 'Carol M. Black', 'Charles Dodds', 'Charles Goodall (physician)', 'Charles Wilson, 1st Baron Moran', 'Chief physician', 'Clinical chemistry', 'Clinical neurophysiology', 'Clinical pathology', 'College of Physicians', 'Colorectal surgery', 'Cyril Clarke', 'Cytopathology', 'Dame Commander of the Most Excellent Order of the British Empire', 'Daniel Whistler', 'Dermatology', 'Dictionary of National Biography', 'Digestive system surgery', 'Disaster medicine', 'Diving medicine', 'Doctor of Medicine', 'Doctor of Osteopathic Medicine', 'Douglas Black (physician)', 'Edward Alston', 'Edward Browne (physician)', 'Edward Wotton (zoologist)', 'Emergency medicine', 'Endocrine surgery', 'Endocrinology', 'Evolutionary medicine', 'Eye surgery', 'Family medicine', 'Francis Glisson', 'Francis Prujean', 'Gastroenterology', 'General practice', 'General surgery', 'George Alberti', 'George Baker, 1st Baronet', 'George Ent', 'George Owen (physician)', 'George Rogers (physician)', 'Geriatrics', 'Gynaecology', 'Gynecologic oncology', 'Hampshire', 'Hand surgery', 'Harveian oration', 'Hematology', 'Henry Atkins (physician)', 'Henry Plumptre', 'Henry Revell Reynolds', 'Hepatology', 'History of medicine', 'Hospital medicine', 'Ian Gilmore', 'Immunology', 'Infectious diseases (medical specialty)', 'Intensive care medicine', 'Internal medicine', 'Interventional radiology', 'James Alderson', 'James Jurin', 'James Risdon Bennett', 'Jane Dacre', 'John Argent', 'John Ayrton Paris', 'John Bateman (physician)', 'John Burgess (physician)', 'John Caius', 'John Clark (17th-century physician)', 'John Clement (physician)', 'John Fryer (physician, died 1563)', 'John Giffard (physician)', 'John Latham (physician)', 'John Lawson (physician)', 'John Micklethwaite', 'John Symings', 'Josiah Clerk', 'Knight Commander of the Royal Victorian Order', 'Leeds', 'Leslie Turnberg, Baron Turnberg', 'List of extant baronetcies', 'List of presidents of the Royal College of Physicians', 'London', 'Lumleian Lectures', 'MD–PhD', 'Margaret Turner-Warwick', 'Marshall Hall (physiologist)', 'Mass gathering medicine', 'Master of Medicine', 'Master of Surgery', 'Maternal–fetal medicine', 'Max Rosenheim, Baron Rosenheim', 'Medical Scientist Training Program', 'Medical diagnosis', 'Medical education', 'Medical genetics', 'Medical microbiology', 'Medical school', 'Medical specialty', 'Medicine', 'Molecular oncology', 'Nanomedicine', 'Narcology', 'Neonatology', 'Nephrology', 'Neurologist', 'Neurology', 'Neuroradiology', 'Neurosurgery', 'Neurosurgical anesthesia', 'Nuclear medicine', 'Obstetric anesthesiology', 'Obstetrics', 'Obstetrics and gynaecology', 'Occupational medicine', 'Oncology', 'Ophthalmology', 'Oral and maxillofacial surgery', 'Oral medicine', 'Organ transplantation', 'Orthopedic surgery', 'Othowell Meverall', 'Otorhinolaryngology', 'Outline of medicine', 'Pain management', 'Palliative care', 'Pathology', 'Pediatric surgery', 'Pediatrics', 'Personalized medicine', 'Phlebologist', 'Physical medicine and rehabilitation', 'Physician', 'Plastic surgery', 'Preventive healthcare', 'Prison healthcare', 'Psychiatry', 'Public domain', 'Public health', 'Pulmonary congestion', 'Pulmonology', 'Radiation therapy', 'Radiology', 'Raymond Hoffenberg', 'Reproductive endocrinology and infertility', 'Reproductive medicine', 'Reproductive surgery', 'Reynolds Baronets', 'Reynolds baronets', 'Rheumatology', 'Richard Bartlot', 'Richard Caldwell', 'Richard Forster (physician)', 'Richard Master', 'Richard Palmer (physician)', 'Richard Smith (physician)', 'Richard Thompson (physician)', 'Richard Tyson (physician, 1680–1750)', 'Robert Huick', 'Robert Platt, Baron Platt', 'Roger Giffard', 'Romsey', 'Royal College of Physicians', 'Royal Medical and Chirurgical Society', 'Royal Society', 'Rural health', 'Samuel Collins (physician, born 1618)', 'Samuel Wilks', 'Sarah Clarke (doctor)', 'Sexual medicine', 'Simeon Fox', 'Sir Andrew Clark, 1st Baronet', 'Sir Andrew Goddard', 'Sir Francis Milman, 1st Baronet', 'Sir Frederick Taylor, 1st Baronet', 'Sir George Burrows, 1st Baronet', 'Sir Hans Sloane', 'Sir Henry Halford, 1st Baronet', 'Sir Humphry Rolleston, 1st Baronet', 'Sir John Bradford, 1st Baronet', 'Sir John Russell Reynolds, 1st Baronet', 'Sir Norman Moore, 1st Baronet', 'Sir Richard Powell, 1st Baronet', 'Sir Robert Hutchison, 1st Baronet', 'Sir Thomas Barlow, 1st Baronet', 'Sir William Church, 1st Baronet', 'Sir William Paddy', 'Sleep medicine', 'Sports medicine', 'Subspecialty', 'Surgery', 'Surgical oncology', 'The Hospital for Sick Children, Toronto', 'The London Gazette', 'Therapy', 'Thomas Bentley (physician)', 'Thomas Burwell', 'Thomas Coxe', 'Thomas Francis (16th-century physician)', 'Thomas Gisborne (physician)', 'Thomas Langton (physician)', 'Thomas Lawrence (physician)', 'Thomas Linacre', 'Thomas Mayo (physician)', 'Thomas Millington (physician)', 'Thomas Moundeford', 'Thomas Pellett', 'Thomas Reeve (physician)', 'Thomas Watson (physician)', 'Thomas Witherley', 'Traditional medicine', 'Transfusion medicine', 'Trauma surgery', 'Travel medicine', 'Tropical medicine', 'University College, London', 'University College Hospital', 'University of London', 'Urogynecology', 'Urology', 'Vascular surgery', 'Venereology', 'Veterinary medicine', 'Walter Charleton', 'Walter Hayle Walshe', 'Walter Russell Brain', 'Westminster Hospital', 'William Baronsdale', 'William Battie', 'William Browne (physician)', 'William Dawes (physician)', 'William Freeman (physician)', 'William Gilbert (physicist)', 'William Jenner, 1st Baronet', 'William Pitcairn', 'William Wasey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_embeddings = model.encode(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"the latter year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = model.encode(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = -1; \n",
    "new_word = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,local in enumerate(list_embeddings):\n",
    "    if np.dot(word_embedding,local)>maxi:\n",
    "        maxi = np.dot(word_embedding,local)\n",
    "        new_word = lst[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = \"albert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2 = \"albert Einstien\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.dot(model.encode(word1),model.encode(word2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def process_sentence_set_wiki(task_args):\n",
    "    # Extract the index, sent_sets, and subject_dict from the arguments\n",
    "    index, sent_sets, subject_dict = task_args\n",
    "    # Process the sentence set (this is a placeholder for your actual logic)\n",
    "    fraction = 0.5  # Example result\n",
    "    local_pair_and_values = \"example_pair_and_values\"  # Example result\n",
    "    return index, fraction, local_pair_and_values\n",
    "\n",
    "# Example data for the task arguments\n",
    "pairs = [(\"sentence_set1\", \"sentence_set2\"), (\"sentence_set3\", \"sentence_set4\")]\n",
    "subject_dict = {\"subject1\": \"value1\", \"subject2\": \"value2\"}\n",
    "\n",
    "# Using ThreadPoolExecutor\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n",
    "    task_args = [(index, sent_sets, subject_dict) for index, sent_sets in enumerate(pairs)]\n",
    "    results = list(executor.map(process_sentence_set_wiki, task_args))\n",
    "\n",
    "# Extract and use the results\n",
    "for index, fraction, local_pair_and_values in results:\n",
    "    print(f\"Index: {index}, Fraction: {fraction}, Pair and Values: {local_pair_and_values}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
